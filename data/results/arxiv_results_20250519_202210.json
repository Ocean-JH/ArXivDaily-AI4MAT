[
  {
    "id": "http://arxiv.org/abs/2505.10994v1",
    "title": "Space Group Equivariant Crystal Diffusion",
    "authors": [
      "Rees Chang",
      "Angela Pak",
      "Alex Guerra",
      "Ni Zhan",
      "Nick Richardson",
      "Elif Ertekin",
      "Ryan P. Adams"
    ],
    "summary": "Accelerating inverse design of crystalline materials with generative models\nhas significant implications for a range of technologies. Unlike other atomic\nsystems, 3D crystals are invariant to discrete groups of isometries called the\nspace groups. Crucially, these space group symmetries are known to heavily\ninfluence materials properties. We propose SGEquiDiff, a crystal generative\nmodel which naturally handles space group constraints with space group\ninvariant likelihoods. SGEquiDiff consists of an SE(3)-invariant, telescoping\ndiscrete sampler of crystal lattices; permutation-invariant, transformer-based\nautoregressive sampling of Wyckoff positions, elements, and numbers of\nsymmetrically unique atoms; and space group equivariant diffusion of atomic\ncoordinates. We show that space group equivariant vector fields automatically\nlive in the tangent spaces of the Wyckoff positions. SGEquiDiff achieves\nstate-of-the-art performance on standard benchmark datasets as assessed by\nquantitative proxy metrics and quantum mechanical calculations.",
    "published": "2025-05-16T08:45:04+00:00",
    "updated": "2025-05-16T08:45:04+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2505.10994v1",
    "short_id": "2505.10994v1",
    "url": "http://arxiv.org/abs/2505.10994v1"
  },
  {
    "id": "http://arxiv.org/abs/2504.13048v1",
    "title": "Design Topological Materials by Reinforcement Fine-Tuned Generative Model",
    "authors": [
      "Haosheng Xu",
      "Dongheng Qian",
      "Zhixuan Liu",
      "Yadong Jiang",
      "Jing Wang"
    ],
    "summary": "Topological insulators (TIs) and topological crystalline insulators (TCIs)\nare materials with unconventional electronic properties, making their discovery\nhighly valuable for practical applications. However, such materials,\nparticularly those with a full band gap, remain scarce. Given the limitations\nof traditional approaches that scan known materials for candidates, we focus on\nthe generation of new topological materials through a generative model.\nSpecifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained\ngenerative model, thereby aligning the model's objectives with our material\ndesign goals. We demonstrate that ReFT is effective in enhancing the model's\nability to generate TIs and TCIs, with minimal compromise on the stability of\nthe generated materials. Using the fine-tuned model, we successfully identify a\nlarge number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a\nrepresentative example--a TI with a full band gap of 0.26 eV, ranking among the\nlargest known in this category.",
    "published": "2025-04-17T16:05:24+00:00",
    "updated": "2025-04-17T16:05:24+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2504.13048v1",
    "short_id": "2504.13048v1",
    "url": "http://arxiv.org/abs/2504.13048v1"
  },
  {
    "id": "http://arxiv.org/abs/2503.23794v1",
    "title": "Force-Free Molecular Dynamics Through Autoregressive Equivariant Networks",
    "authors": [
      "Fabian L. Thiemann",
      "Thiago Reschützegger",
      "Massimiliano Esposito",
      "Tseden Taddese",
      "Juan D. Olarte-Plata",
      "Fausto Martelli"
    ],
    "summary": "Molecular dynamics (MD) simulations play a crucial role in scientific\nresearch. Yet their computational cost often limits the timescales and system\nsizes that can be explored. Most data-driven efforts have been focused on\nreducing the computational cost of accurate interatomic forces required for\nsolving the equations of motion. Despite their success, however, these machine\nlearning interatomic potentials (MLIPs) are still bound to small time-steps. In\nthis work, we introduce TrajCast, a transferable and data-efficient framework\nbased on autoregressive equivariant message passing networks that directly\nupdates atomic positions and velocities lifting the constraints imposed by\ntraditional numerical integration. We benchmark our framework across various\nsystems, including a small molecule, crystalline material, and bulk liquid,\ndemonstrating excellent agreement with reference MD simulations for structural,\ndynamical, and energetic properties. Depending on the system, TrajCast allows\nfor forecast intervals up to $30\\times$ larger than traditional MD time-steps,\ngenerating over 15 ns of trajectory data per day for a solid with more than\n4,000 atoms. By enabling efficient large-scale simulations over extended\ntimescales, TrajCast can accelerate materials discovery and explore physical\nphenomena beyond the reach of traditional simulations and experiments. An\nopen-source implementation of TrajCast is accessible under\nhttps://github.com/IBM/trajcast.",
    "published": "2025-03-31T07:14:32+00:00",
    "updated": "2025-03-31T07:14:32+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "25 pages total (19 manuscript, 6 SI). 5 figures in manuscript, 3\n  figures and 2 tables in SI",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2503.23794v1",
    "short_id": "2503.23794v1",
    "url": "http://arxiv.org/abs/2503.23794v1"
  },
  {
    "id": "http://arxiv.org/abs/2502.02189v2",
    "title": "deCIFer: Crystal Structure Prediction from Powder Diffraction Data using Autoregressive Language Models",
    "authors": [
      "Frederik Lizak Johansen",
      "Ulrik Friis-Jensen",
      "Erik Bjørnager Dam",
      "Kirsten Marie Ørnsbjerg Jensen",
      "Rocío Mercado",
      "Raghavendra Selvan"
    ],
    "summary": "Novel materials drive progress across applications from energy storage to\nelectronics. Automated characterization of material structures with machine\nlearning methods offers a promising strategy for accelerating this key step in\nmaterial design. In this work, we introduce an autoregressive language model\nthat performs crystal structure prediction (CSP) from powder diffraction data.\nThe presented model, deCIFer, generates crystal structures in the widely used\nCrystallographic Information File (CIF) format and can be conditioned on powder\nX-ray diffraction (PXRD) data. Unlike earlier works that primarily rely on\nhigh-level descriptors like composition, deCIFer performs CSP from diffraction\ndata. We train deCIFer on nearly 2.3M unique crystal structures and validate on\ndiverse sets of PXRD patterns for characterizing challenging inorganic crystal\nsystems. Qualitative and quantitative assessments using the residual weighted\nprofile and Wasserstein distance show that deCIFer produces structures that\nmore accurately match the target diffraction data when conditioned, compared to\nthe unconditioned case. Notably, deCIFer can achieve a 94% match rate on unseen\ndata. deCIFer bridges experimental diffraction data with computational CSP,\nlending itself as a powerful tool for crystal structure characterization and\naccelerating materials discovery.",
    "published": "2025-02-04T10:09:47+00:00",
    "updated": "2025-02-10T08:39:50+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 17 figures, 6 tables. v2: Figure 8 revision",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2502.02189v2",
    "short_id": "2502.02189v2",
    "url": "http://arxiv.org/abs/2502.02189v2"
  },
  {
    "id": "http://arxiv.org/abs/2502.02016v1",
    "title": "A Periodic Bayesian Flow for Material Generation",
    "authors": [
      "Hanlin Wu",
      "Yuxuan Song",
      "Jingjing Gong",
      "Ziyao Cao",
      "Yawen Ouyang",
      "Jianbing Zhang",
      "Hao Zhou",
      "Wei-Ying Ma",
      "Jingjing Liu"
    ],
    "summary": "Generative modeling of crystal data distribution is an important yet\nchallenging task due to the unique periodic physical symmetry of crystals.\nDiffusion-based methods have shown early promise in modeling crystal\ndistribution. More recently, Bayesian Flow Networks were introduced to\naggregate noisy latent variables, resulting in a variance-reduced parameter\nspace that has been shown to be advantageous for modeling Euclidean data\ndistributions with structural constraints (Song et al., 2023). Inspired by\nthis, we seek to unlock its potential for modeling variables located in\nnon-Euclidean manifolds e.g. those within crystal structures, by overcoming\nchallenging theoretical issues. We introduce CrysBFN, a novel crystal\ngeneration method by proposing a periodic Bayesian flow, which essentially\ndiffers from the original Gaussian-based BFN by exhibiting non-monotonic\nentropy dynamics. To successfully realize the concept of periodic Bayesian\nflow, CrysBFN integrates a new entropy conditioning mechanism and empirically\ndemonstrates its significance compared to time-conditioning. Extensive\nexperiments over both crystal ab initio generation and crystal structure\nprediction tasks demonstrate the superiority of CrysBFN, which consistently\nachieves new state-of-the-art on all benchmarks. Surprisingly, we found that\nCrysBFN enjoys a significant improvement in sampling efficiency, e.g., ~100x\nspeedup 10 v.s. 2000 steps network forwards) compared with previous\ndiffusion-based methods on MP-20 dataset. Code is available at\nhttps://github.com/wu-han-lin/CrysBFN.",
    "published": "2025-02-04T05:07:13+00:00",
    "updated": "2025-02-04T05:07:13+00:00",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR25",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2502.02016v1",
    "short_id": "2502.02016v1",
    "url": "http://arxiv.org/abs/2502.02016v1"
  },
  {
    "id": "http://arxiv.org/abs/2501.06171v1",
    "title": "Machine Learning Force-Field Approach for Itinerant Electron Magnets",
    "authors": [
      "Sheng Zhang",
      "Yunhao Fan",
      "Kotaro Shimizu",
      "Gia-Wei Chern"
    ],
    "summary": "We review the recent development of machine-learning (ML) force-field\nframeworks for Landau-Lifshitz-Gilbert (LLG) dynamics simulations of itinerant\nelectron magnets, focusing on the general theory and implementations of\nsymmetry-invariant representations of spin configurations. The crucial\nproperties that such magnetic descriptors must satisfy are differentiability\nwith respect to spin rotations and invariance to both lattice point-group\nsymmetry and internal spin rotation symmetry. We propose an efficient\nimplementation based on the concept of reference irreducible representations,\nmodified from the group-theoretical power-spectrum and bispectrum methods. The\nML framework is demonstrated using the s-d models, which are widely applied in\nspintronics research. We show that LLG simulations based on local fields\npredicted by the trained ML models successfully reproduce representative\nnon-collinear spin structures, including 120$^\\circ$, tetrahedral, and skyrmion\ncrystal orders of the triangular-lattice s-d models. Large-scale thermal quench\nsimulations enabled by ML models further reveal intriguing freezing dynamics\nand glassy stripe states consisting of skyrmions and bi-merons. Our work\nhighlights the utility of ML force-field approach to dynamical modeling of\ncomplex spin orders in itinerant electron magnets.",
    "published": "2025-01-10T18:50:45+00:00",
    "updated": "2025-01-10T18:50:45+00:00",
    "categories": [
      "cond-mat.str-el",
      "cs.LG",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.str-el",
    "comment": "18 pages, 8 figures",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2501.06171v1",
    "short_id": "2501.06171v1",
    "url": "http://arxiv.org/abs/2501.06171v1"
  },
  {
    "id": "http://arxiv.org/abs/2412.20796v2",
    "title": "FastCHGNet: Training one Universal Interatomic Potential to 1.5 Hours with 32 GPUs",
    "authors": [
      "Yuanchang Zhou",
      "Siyu Hu",
      "Chen Wang",
      "Lin-Wang Wang",
      "Guangming Tan",
      "Weile Jia"
    ],
    "summary": "Graph neural network universal interatomic potentials (GNN-UIPs) have\ndemonstrated remarkable generalization and transfer capabilities in material\ndiscovery and property prediction. These models can accelerate molecular\ndynamics (MD) simulation by several orders of magnitude while maintaining\n\\textit{ab initio} accuracy, making them a promising new paradigm in material\nsimulations. One notable example is Crystal Hamiltonian Graph Neural Network\n(CHGNet), pretrained on the energies, forces, stresses, and magnetic moments\nfrom the MPtrj dataset, representing a state-of-the-art GNN-UIP model for\ncharge-informed MD simulations. However, training the CHGNet model is\ntime-consuming(8.3 days on one A100 GPU) for three reasons: (i) requiring\nmulti-layer propagation to reach more distant atom information, (ii) requiring\nsecond-order derivatives calculation to finish weights updating and (iii) the\nimplementation of reference CHGNet does not fully leverage the computational\ncapabilities. This paper introduces FastCHGNet, an optimized CHGNet, with three\ncontributions: Firstly, we design innovative Force/Stress Readout modules to\ndecompose Force/Stress prediction. Secondly, we adopt massive optimizations\nsuch as kernel fusion, redundancy bypass, etc, to exploit GPU computation power\nsufficiently. Finally, we extend CHGNet to support multiple GPUs and propose a\nload-balancing technique to enhance GPU utilization. Numerical results show\nthat FastCHGNet reduces memory footprint by a factor of 3.59. The final\ntraining time of FastCHGNet can be decreased to \\textbf{1.53 hours} on 32 GPUs\nwithout sacrificing model accuracy.",
    "published": "2024-12-30T08:38:09+00:00",
    "updated": "2025-03-14T08:01:35+00:00",
    "categories": [
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2412.20796v2",
    "short_id": "2412.20796v2",
    "url": "http://arxiv.org/abs/2412.20796v2"
  },
  {
    "id": "http://arxiv.org/abs/2410.20976v1",
    "title": "Large Language Model-Guided Prediction Toward Quantum Materials Synthesis",
    "authors": [
      "Ryotaro Okabe",
      "Zack West",
      "Abhijatmedhi Chotrattanapituk",
      "Mouyang Cheng",
      "Denisse Córdova Carrizales",
      "Weiwei Xie",
      "Robert J. Cava",
      "Mingda Li"
    ],
    "summary": "The synthesis of inorganic crystalline materials is essential for modern\ntechnology, especially in quantum materials development. However, designing\nefficient synthesis workflows remains a significant challenge due to the\nprecise experimental conditions and extensive trial and error. Here, we present\na framework using large language models (LLMs) to predict synthesis pathways\nfor inorganic materials, including quantum materials. Our framework contains\nthree models: LHS2RHS, predicting products from reactants; RHS2LHS, predicting\nreactants from products; and TGT2CEQ, generating full chemical equations for\ntarget compounds. Fine-tuned on a text-mined synthesis database, our model\nraises accuracy from under 40% with pretrained models, to under 80% using\nconventional fine-tuning, and further to around 90% with our proposed\ngeneralized Tanimoto similarity, while maintaining robust to additional\nsynthesis steps. Our model further demonstrates comparable performance across\nmaterials with varying degrees of quantumness quantified using quantum weight,\nindicating that LLMs offer a powerful tool to predict balanced chemical\nequations for quantum materials discovery.",
    "published": "2024-10-28T12:50:46+00:00",
    "updated": "2024-10-28T12:50:46+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "66 pages total, 6 main figures + 3 supplementary figures",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2410.20976v1",
    "short_id": "2410.20976v1",
    "url": "http://arxiv.org/abs/2410.20976v1"
  },
  {
    "id": "http://arxiv.org/abs/2409.13851v1",
    "title": "Learning Ordering in Crystalline Materials with Symmetry-Aware Graph Neural Networks",
    "authors": [
      "Jiayu Peng",
      "James Damewood",
      "Jessica Karaguesian",
      "Jaclyn R. Lunger",
      "Rafael Gómez-Bombarelli"
    ],
    "summary": "Graph convolutional neural networks (GCNNs) have become a machine learning\nworkhorse for screening the chemical space of crystalline materials in fields\nsuch as catalysis and energy storage, by predicting properties from structures.\nMulticomponent materials, however, present a unique challenge since they can\nexhibit chemical (dis)order, where a given lattice structure can encompass a\nvariety of elemental arrangements ranging from highly ordered structures to\nfully disordered solid solutions. Critically, properties like stability,\nstrength, and catalytic performance depend not only on structures but also on\norderings. To enable rigorous materials design, it is thus critical to ensure\nGCNNs are capable of distinguishing among atomic orderings. However, the\nordering-aware capability of GCNNs has been poorly understood. Here, we\nbenchmark various neural network architectures for capturing the\nordering-dependent energetics of multicomponent materials in a custom-made\ndataset generated with high-throughput atomistic simulations. Conventional\nsymmetry-invariant GCNNs were found unable to discern the structural difference\nbetween the diverse symmetrically inequivalent atomic orderings of the same\nmaterial, while symmetry-equivariant model architectures could inherently\npreserve and differentiate the distinct crystallographic symmetries of various\norderings.",
    "published": "2024-09-20T18:53:48+00:00",
    "updated": "2024-09-20T18:53:48+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2409.13851v1",
    "short_id": "2409.13851v1",
    "url": "http://arxiv.org/abs/2409.13851v1"
  },
  {
    "id": "http://arxiv.org/abs/2406.10796v2",
    "title": "Ab Initio Structure Solutions from Nanocrystalline Powder Diffraction Data",
    "authors": [
      "Gabe Guo",
      "Tristan Saidi",
      "Maxwell Terban",
      "Michele Valsecchi",
      "Simon JL Billinge",
      "Hod Lipson"
    ],
    "summary": "A major challenge in materials science is the determination of the structure\nof nanometer sized objects. Here we present a novel approach that uses a\ngenerative machine learning model based on diffusion processes that is trained\non 45,229 known structures. The model factors both the measured diffraction\npattern as well as relevant statistical priors on the unit cell of atomic\ncluster structures. Conditioned only on the chemical formula and the\ninformation-scarce finite-size broadened powder diffraction pattern, we find\nthat our model, PXRDnet, can successfully solve simulated nanocrystals as small\nas 10 angstroms across 200 materials of varying symmetry and complexity,\nincluding structures from all seven crystal systems. We show that our model can\nsuccessfully and verifiably determine structural candidates four out of five\ntimes, with average error among these candidates being only 7% (as measured by\npost-Rietveld refinement R-factor). Furthermore, PXRDnet is capable of solving\nstructures from noisy diffraction patterns gathered in real-world experiments.\nWe suggest that data driven approaches, bootstrapped from theoretical\nsimulation, will ultimately provide a path towards determining the structure of\npreviously unsolved nano-materials.",
    "published": "2024-06-16T03:45:03+00:00",
    "updated": "2024-10-31T17:29:37+00:00",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2406.10796v2",
    "short_id": "2406.10796v2",
    "url": "http://arxiv.org/abs/2406.10796v2"
  },
  {
    "id": "http://arxiv.org/abs/2403.08147v3",
    "title": "Representing Molecules as Random Walks Over Interpretable Grammars",
    "authors": [
      "Michael Sun",
      "Minghao Guo",
      "Weize Yuan",
      "Veronika Thost",
      "Crystal Elaine Owens",
      "Aristotle Franklin Grosz",
      "Sharvaa Selvan",
      "Katelyn Zhou",
      "Hassan Mohiuddin",
      "Benjamin J Pedretti",
      "Zachary P Smith",
      "Jie Chen",
      "Wojciech Matusik"
    ],
    "summary": "Recent research in molecular discovery has primarily been devoted to small,\ndrug-like molecules, leaving many similarly important applications in material\ndesign without adequate technology. These applications often rely on more\ncomplex molecular structures with fewer examples that are carefully designed\nusing known substructures. We propose a data-efficient and interpretable model\nfor representing and reasoning over such molecules in terms of graph grammars\nthat explicitly describe the hierarchical design space featuring motifs to be\nthe design basis. We present a novel representation in the form of random walks\nover the design space, which facilitates both molecule generation and property\nprediction. We demonstrate clear advantages over existing methods in terms of\nperformance, efficiency, and synthesizability of predicted molecules, and we\nprovide detailed insights into the method's chemical interpretability.",
    "published": "2024-03-13T00:19:06+00:00",
    "updated": "2024-06-03T02:43:24+00:00",
    "categories": [
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": null,
    "journal_ref": "ICML 2024",
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2403.08147v3",
    "short_id": "2403.08147v3",
    "url": "http://arxiv.org/abs/2403.08147v3"
  },
  {
    "id": "http://arxiv.org/abs/2402.13221v2",
    "title": "CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning",
    "authors": [
      "Ulrik Friis-Jensen",
      "Frederik L. Johansen",
      "Andy S. Anker",
      "Erik B. Dam",
      "Kirsten M. Ø. Jensen",
      "Raghavendra Selvan"
    ],
    "summary": "Advances in graph machine learning (ML) have been driven by applications in\nchemistry as graphs have remained the most expressive representations of\nmolecules. While early graph ML methods focused primarily on small organic\nmolecules, recently, the scope of graph ML has expanded to include inorganic\nmaterials. Modelling the periodicity and symmetry of inorganic crystalline\nmaterials poses unique challenges, which existing graph ML methods are unable\nto address. Moving to inorganic nanomaterials increases complexity as the scale\nof number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of\nexisting graph ML focuses on characterising molecules and materials by\npredicting target properties with graphs as input. However, the most exciting\napplications of graph ML will be in their generative capabilities, which is\ncurrently not at par with other domains such as images or text.\n  We invite the graph ML community to address these open challenges by\npresenting two new chemically-informed large-scale inorganic (CHILI)\nnanomaterials datasets: A medium-scale dataset (with overall >6M nodes, >49M\nedges) of mono-metallic oxide nanomaterials generated from 12 selected crystal\ntypes (CHILI-3K) and a large-scale dataset (with overall >183M nodes, >1.2B\nedges) of nanomaterials generated from experimentally determined crystal\nstructures (CHILI-100K). We define 11 property prediction tasks and 6 structure\nprediction tasks, which are of special interest for nanomaterial research. We\nbenchmark the performance of a wide array of baseline methods and use these\nbenchmarking results to highlight areas which need future work. To the best of\nour knowledge, CHILI-3K and CHILI-100K are the first open-source nanomaterial\ndatasets of this scale -- both on the individual graph level and of the dataset\nas a whole -- and the only nanomaterials datasets with high structural and\nelemental diversity.",
    "published": "2024-02-20T18:32:27+00:00",
    "updated": "2024-02-21T08:07:13+00:00",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 15 figures, 8 tables. Dataset is available at\n  https://github.com/UlrikFriisJensen/CHILI",
    "journal_ref": "KDD '24: Proceedings of the 30th ACM SIGKDD Conference on\n  Knowledge Discovery and Data Mining. 2024",
    "doi": "10.1145/3637528.3671538",
    "pdf_url": "http://arxiv.org/pdf/2402.13221v2",
    "short_id": "2402.13221v2",
    "url": "http://arxiv.org/abs/2402.13221v2"
  },
  {
    "id": "http://arxiv.org/abs/2312.15136v1",
    "title": "Towards End-to-End Structure Solutions from Information-Compromised Diffraction Data via Generative Deep Learning",
    "authors": [
      "Gabe Guo",
      "Judah Goldfeder",
      "Ling Lan",
      "Aniv Ray",
      "Albert Hanming Yang",
      "Boyuan Chen",
      "Simon JL Billinge",
      "Hod Lipson"
    ],
    "summary": "The revolution in materials in the past century was built on a knowledge of\nthe atomic arrangements and the structure-property relationship. The sine qua\nnon for obtaining quantitative structural information is single crystal\ncrystallography. However, increasingly we need to solve structures in cases\nwhere the information content in our input signal is significantly degraded,\nfor example, due to orientational averaging of grains, finite size effects due\nto nanostructure, and mixed signals due to sample heterogeneity. Understanding\nthe structure property relationships in such situations is, if anything, more\nimportant and insightful, yet we do not have robust approaches for\naccomplishing it. In principle, machine learning (ML) and deep learning (DL)\nare promising approaches since they augment information in the degraded input\nsignal with prior knowledge learned from large databases of already known\nstructures. Here we present a novel ML approach, a variational query-based\nmulti-branch deep neural network that has the promise to be a robust but\ngeneral tool to address this problem end-to-end. We demonstrate the approach on\ncomputed powder x-ray diffraction (PXRD), along with partial chemical\ncomposition information, as input. We choose as a structural representation a\nmodified electron density we call the Cartesian mapped electron density (CMED),\nthat straightforwardly allows our ML model to learn material structures across\ndifferent chemistries, symmetries and crystal systems. When evaluated on\ntheoretically simulated data for the cubic and trigonal crystal systems, the\nsystem achieves up to $93.4\\%$ average similarity with the ground truth on\nunseen materials, both with known and partially-known chemical composition\ninformation, showing great promise for successful structure solution even from\ndegraded and incomplete input data.",
    "published": "2023-12-23T02:17:27+00:00",
    "updated": "2023-12-23T02:17:27+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "physics.comp-ph",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2312.15136v1",
    "short_id": "2312.15136v1",
    "url": "http://arxiv.org/abs/2312.15136v1"
  },
  {
    "id": "http://arxiv.org/abs/2311.05407v1",
    "title": "Data Distillation for Neural Network Potentials toward Foundational Dataset",
    "authors": [
      "Gang Seob Jung",
      "Sangkeun Lee",
      "Jong Youl Choi"
    ],
    "summary": "Machine learning (ML) techniques and atomistic modeling have rapidly\ntransformed materials design and discovery. Specifically, generative models can\nswiftly propose promising materials for targeted applications. However, the\npredicted properties of materials through the generative models often do not\nmatch with calculated properties through ab initio calculations. This\ndiscrepancy can arise because the generated coordinates are not fully relaxed,\nwhereas the many properties are derived from relaxed structures. Neural\nnetwork-based potentials (NNPs) can expedite the process by providing relaxed\nstructures from the initially generated ones. Nevertheless, acquiring data to\ntrain NNPs for this purpose can be extremely challenging as it needs to\nencompass previously unknown structures. This study utilized extended ensemble\nmolecular dynamics (MD) to secure a broad range of liquid- and solid-phase\nconfigurations in one of the metallic systems, nickel. Then, we could\nsignificantly reduce them through active learning without losing much accuracy.\nWe found that the NNP trained from the distilled data could predict different\nenergy-minimized closed-pack crystal structures even though those structures\nwere not explicitly part of the initial data. Furthermore, the data can be\ntranslated to other metallic systems (aluminum and niobium), without repeating\nthe sampling and distillation processes. Our approach to data acquisition and\ndistillation has demonstrated the potential to expedite NNP development and\nenhance materials design and discovery by integrating generative models.",
    "published": "2023-11-09T14:41:45+00:00",
    "updated": "2023-11-09T14:41:45+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "physics.comp-ph",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2311.05407v1",
    "short_id": "2311.05407v1",
    "url": "http://arxiv.org/abs/2311.05407v1"
  },
  {
    "id": "http://arxiv.org/abs/2310.10695v1",
    "title": "Data-Driven Score-Based Models for Generating Stable Structures with Adaptive Crystal Cells",
    "authors": [
      "Arsen Sultanov",
      "Jean-Claude Crivello",
      "Tabea Rebafka",
      "Nataliya Sokolovska"
    ],
    "summary": "The discovery of new functional and stable materials is a big challenge due\nto its complexity. This work aims at the generation of new crystal structures\nwith desired properties, such as chemical stability and specified chemical\ncomposition, by using machine learning generative models. Compared to the\ngeneration of molecules, crystal structures pose new difficulties arising from\nthe periodic nature of the crystal and from the specific symmetry constraints\nrelated to the space group. In this work, score-based probabilistic models\nbased on annealed Langevin dynamics, which have shown excellent performance in\nvarious applications, are adapted to the task of crystal generation. The\nnovelty of the presented approach resides in the fact that the lattice of the\ncrystal cell is not fixed. During the training of the model, the lattice is\nlearned from the available data, whereas during the sampling of a new chemical\nstructure, two denoising processes are used in parallel to generate the lattice\nalong the generation of the atomic positions. A multigraph crystal\nrepresentation is introduced that respects symmetry constraints, yielding\ncomputational advantages and a better quality of the sampled structures. We\nshow that our model is capable of generating new candidate structures in any\nchosen chemical system and crystal group without any additional training. To\nillustrate the functionality of the proposed method, a comparison of our model\nto other recent generative models, based on descriptor-based metrics, is\nprovided.",
    "published": "2023-10-16T02:53:24+00:00",
    "updated": "2023-10-16T02:53:24+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "primary_category": "physics.comp-ph",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2310.10695v1",
    "short_id": "2310.10695v1",
    "url": "http://arxiv.org/abs/2310.10695v1"
  },
  {
    "id": "http://arxiv.org/abs/2310.04925v2",
    "title": "Crystal-GFN: sampling crystals with desirable properties and constraints",
    "authors": [
      "Mila AI4Science",
      "Alex Hernandez-Garcia",
      "Alexandre Duval",
      "Alexandra Volokhova",
      "Yoshua Bengio",
      "Divya Sharma",
      "Pierre Luc Carrier",
      "Yasmine Benabed",
      "Michał Koziarski",
      "Victor Schmidt"
    ],
    "summary": "Accelerating material discovery holds the potential to greatly help mitigate\nthe climate crisis. Discovering new solid-state materials such as\nelectrocatalysts, super-ionic conductors or photovoltaic materials can have a\ncrucial impact, for instance, in improving the efficiency of renewable energy\nproduction and storage. In this paper, we introduce Crystal-GFN, a generative\nmodel of crystal structures that sequentially samples structural properties of\ncrystalline materials, namely the space group, composition and lattice\nparameters. This domain-inspired approach enables the flexible incorporation of\nphysical and structural hard constraints, as well as the use of any available\npredictive model of a desired physicochemical property as an objective\nfunction. To design stable materials, one must target the candidates with the\nlowest formation energy. Here, we use as objective the formation energy per\natom of a crystal structure predicted by a new proxy machine learning model\ntrained on MatBench. The results demonstrate that Crystal-GFN is able to sample\nhighly diverse crystals with low (median -3.1 eV/atom) predicted formation\nenergy.",
    "published": "2023-10-07T21:36:55+00:00",
    "updated": "2023-12-13T16:24:44+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "comment": "Main paper (10 pages) + references + appendix",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2310.04925v2",
    "short_id": "2310.04925v2",
    "url": "http://arxiv.org/abs/2310.04925v2"
  },
  {
    "id": "http://arxiv.org/abs/2306.09375v1",
    "title": "Symmetry-Informed Geometric Representation for Molecules, Proteins, and Crystalline Materials",
    "authors": [
      "Shengchao Liu",
      "Weitao Du",
      "Yanjing Li",
      "Zhuoxinran Li",
      "Zhiling Zheng",
      "Chenru Duan",
      "Zhiming Ma",
      "Omar Yaghi",
      "Anima Anandkumar",
      "Christian Borgs",
      "Jennifer Chayes",
      "Hongyu Guo",
      "Jian Tang"
    ],
    "summary": "Artificial intelligence for scientific discovery has recently generated\nsignificant interest within the machine learning and scientific communities,\nparticularly in the domains of chemistry, biology, and material discovery. For\nthese scientific problems, molecules serve as the fundamental building blocks,\nand machine learning has emerged as a highly effective and powerful tool for\nmodeling their geometric structures. Nevertheless, due to the rapidly evolving\nprocess of the field and the knowledge gap between science (e.g., physics,\nchemistry, & biology) and machine learning communities, a benchmarking study on\ngeometrical representation for such data has not been conducted. To address\nsuch an issue, in this paper, we first provide a unified view of the current\nsymmetry-informed geometric methods, classifying them into three main\ncategories: invariance, equivariance with spherical frame basis, and\nequivariance with vector frame basis. Then we propose a platform, coined\nGeom3D, which enables benchmarking the effectiveness of geometric strategies.\nGeom3D contains 16 advanced symmetry-informed geometric representation models\nand 14 geometric pretraining methods over 46 diverse datasets, including small\nmolecules, proteins, and crystalline materials. We hope that Geom3D can, on the\none hand, eliminate barriers for machine learning researchers interested in\nexploring scientific problems; and, on the other hand, provide valuable\nguidance for researchers in computational chemistry, structural biology, and\nmaterials science, aiding in the informed selection of representation\ntechniques for specific applications.",
    "published": "2023-06-15T05:37:25+00:00",
    "updated": "2023-06-15T05:37:25+00:00",
    "categories": [
      "cs.LG",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2306.09375v1",
    "short_id": "2306.09375v1",
    "url": "http://arxiv.org/abs/2306.09375v1"
  },
  {
    "id": "http://arxiv.org/abs/2307.05380v1",
    "title": "Optimized Crystallographic Graph Generation for Material Science",
    "authors": [
      "Astrid Klipfel",
      "Yaël Frégier",
      "Adlane Sayede",
      "Zied Bouraoui"
    ],
    "summary": "Graph neural networks are widely used in machine learning applied to\nchemistry, and in particular for material science discovery. For crystalline\nmaterials, however, generating graph-based representation from geometrical\ninformation for neural networks is not a trivial task. The periodicity of\ncrystalline needs efficient implementations to be processed in real-time under\na massively parallel environment. With the aim of training graph-based\ngenerative models of new material discovery, we propose an efficient tool to\ngenerate cutoff graphs and k-nearest-neighbours graphs of periodic structures\nwithin GPU optimization. We provide pyMatGraph a Pytorch-compatible framework\nto generate graphs in real-time during the training of neural network\narchitecture. Our tool can update a graph of a structure, making generative\nmodels able to update the geometry and process the updated graph during the\nforward propagation on the GPU side. Our code is publicly available at\nhttps://github.com/aklipf/mat-graph.",
    "published": "2023-06-07T15:30:03+00:00",
    "updated": "2023-06-07T15:30:03+00:00",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2307.05380v1",
    "short_id": "2307.05380v1",
    "url": "http://arxiv.org/abs/2307.05380v1"
  },
  {
    "id": "http://arxiv.org/abs/2302.00485v1",
    "title": "Equivariant Message Passing Neural Network for Crystal Material Discovery",
    "authors": [
      "Astrid Klipfel",
      "Olivier Peltre",
      "Najwa Harrati",
      "Yaël Fregier",
      "Adlane Sayede",
      "Zied Bouraoui"
    ],
    "summary": "Automatic material discovery with desired properties is a fundamental\nchallenge for material sciences. Considerable attention has recently been\ndevoted to generating stable crystal structures. While existing work has shown\nimpressive success on supervised tasks such as property prediction, the\nprogress on unsupervised tasks such as material generation is still hampered by\nthe limited extent to which the equivalent geometric representations of the\nsame crystal are considered. To address this challenge, we propose EMPNN a\nperiodic equivariant message-passing neural network that learns crystal lattice\ndeformation in an unsupervised fashion. Our model equivalently acts on lattice\naccording to the deformation action that must be performed, making it suitable\nfor crystal generation, relaxation and optimisation. We present experimental\nevaluations that demonstrate the effectiveness of our approach.",
    "published": "2023-02-01T14:48:18+00:00",
    "updated": "2023-02-01T14:48:18+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "comment": null,
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2302.00485v1",
    "short_id": "2302.00485v1",
    "url": "http://arxiv.org/abs/2302.00485v1"
  },
  {
    "id": "http://arxiv.org/abs/2202.01566v3",
    "title": "Unified theory of atom-centered representations and message-passing machine-learning schemes",
    "authors": [
      "Jigyasa Nigam",
      "Sergey Pozdnyakov",
      "Guillaume Fraux",
      "Michele Ceriotti"
    ],
    "summary": "Data-driven schemes that associate molecular and crystal structures with\ntheir microscopic properties share the need for a concise, effective\ndescription of the arrangement of their atomic constituents. Many types of\nmodels rely on descriptions of atom-centered environments, that are associated\nwith an atomic property or with an atomic contribution to an extensive\nmacroscopic quantity. Frameworks in this class can be understood in terms of\natom-centered density correlations (ACDC), that are used as a basis for a\nbody-ordered, symmetry-adapted expansion of the targets. Several other schemes,\nthat gather information on the relationship between neighboring atoms using\n\"message-passing\" ideas, cannot be directly mapped to correlations centered\naround a single atom. We generalize the ACDC framework to include\nmulti-centered information, generating representations that provide a complete\nlinear basis to regress symmetric functions of atomic coordinates, and provides\na coherent foundation to systematize our understanding of both atom-centered\nand message-passing, invariant and equivariant machine-learning schemes.",
    "published": "2022-02-03T12:56:22+00:00",
    "updated": "2022-04-01T08:46:41+00:00",
    "categories": [
      "stat.ML",
      "cs.LG",
      "physics.chem-ph"
    ],
    "primary_category": "stat.ML",
    "comment": null,
    "journal_ref": null,
    "doi": "10.1063/5.0087042",
    "pdf_url": "http://arxiv.org/pdf/2202.01566v3",
    "short_id": "2202.01566v3",
    "url": "http://arxiv.org/abs/2202.01566v3"
  },
  {
    "id": "http://arxiv.org/abs/2201.11932v4",
    "title": "Deep Generative Model for Periodic Graphs",
    "authors": [
      "Shiyu Wang",
      "Xiaojie Guo",
      "Liang Zhao"
    ],
    "summary": "Periodic graphs are graphs consisting of repetitive local structures, such as\ncrystal nets and polygon mesh. Their generative modeling has great potential in\nreal-world applications such as material design and graphics synthesis.\nClassical models either rely on domain-specific predefined generation\nprinciples (e.g., in crystal net design), or follow geometry-based prescribed\nrules. Recently, deep generative models has shown great promise in\nautomatically generating general graphs. However, their advancement into\nperiodic graphs have not been well explored due to several key challenges in 1)\nmaintaining graph periodicity; 2) disentangling local and global patterns; and\n3) efficiency in learning repetitive patterns. To address them, this paper\nproposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a\nnew deep generative models for periodic graphs that can automatically learn,\ndisentangle, and generate local and global graph patterns. Specifically, we\ndevelop a new periodic graph encoder consisting of global-pattern encoder and\nlocal-pattern encoder that ensures to disentangle the representation into\nglobal and local semantics. We then propose a new periodic graph decoder\nconsisting of local structure decoder, neighborhood decoder, and global\nstructure decoder, as well as the assembler of their outputs that guarantees\nperiodicity. Moreover, we design a new model learning objective that helps\nensure the invariance of local-semantic representations for the graphs with the\nsame local structure. Comprehensive experimental evaluations have been\nconducted to demonstrate the effectiveness of the proposed method. The code of\nproposed PGD-VAE is availabe at https://github.com/shi-yu-wang/PGD-VAE.",
    "published": "2022-01-28T04:56:28+00:00",
    "updated": "2022-10-06T00:33:20+00:00",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by NeurIPS 2022",
    "journal_ref": null,
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2201.11932v4",
    "short_id": "2201.11932v4",
    "url": "http://arxiv.org/abs/2201.11932v4"
  },
  {
    "id": "http://arxiv.org/abs/2104.11667v4",
    "title": "Deep Learning for Bayesian Optimization of Scientific Problems with High-Dimensional Structure",
    "authors": [
      "Samuel Kim",
      "Peter Y. Lu",
      "Charlotte Loh",
      "Jamie Smith",
      "Jasper Snoek",
      "Marin Soljačić"
    ],
    "summary": "Bayesian optimization (BO) is a popular paradigm for global optimization of\nexpensive black-box functions, but there are many domains where the function is\nnot completely a black-box. The data may have some known structure (e.g.\nsymmetries) and/or the data generation process may be a composite process that\nyields useful intermediate or auxiliary information in addition to the value of\nthe optimization objective. However, surrogate models traditionally employed in\nBO, such as Gaussian Processes (GPs), scale poorly with dataset size and do not\neasily accommodate known structure. Instead, we use Bayesian neural networks, a\nclass of scalable and flexible surrogate models with inductive biases, to\nextend BO to complex, structured problems with high dimensionality. We\ndemonstrate BO on a number of realistic problems in physics and chemistry,\nincluding topology optimization of photonic crystal materials using\nconvolutional neural networks, and chemical property optimization of molecules\nusing graph neural networks. On these complex tasks, we show that neural\nnetworks often outperform GPs as surrogate models for BO in terms of both\nsampling efficiency and computational cost.",
    "published": "2021-04-23T15:46:37+00:00",
    "updated": "2022-12-06T15:16:34+00:00",
    "categories": [
      "cs.LG",
      "physics.app-ph",
      "physics.chem-ph",
      "physics.comp-ph",
      "physics.optics"
    ],
    "primary_category": "cs.LG",
    "comment": "32 pages, 16 figures; published in TMLR",
    "journal_ref": "Transactions on Machine Learning Research (TMLR) September 2022",
    "doi": null,
    "pdf_url": "http://arxiv.org/pdf/2104.11667v4",
    "short_id": "2104.11667v4",
    "url": "http://arxiv.org/abs/2104.11667v4"
  },
  {
    "id": "http://arxiv.org/abs/1907.03222v1",
    "title": "IRNet: A General Purpose Deep Residual Regression Framework for Materials Discovery",
    "authors": [
      "Dipendra Jha",
      "Logan Ward",
      "Zijiang Yang",
      "Christopher Wolverton",
      "Ian Foster",
      "Wei-keng Liao",
      "Alok Choudhary",
      "Ankit Agrawal"
    ],
    "summary": "Materials discovery is crucial for making scientific advances in many\ndomains. Collections of data from experiments and first-principle computations\nhave spurred interest in applying machine learning methods to create predictive\nmodels capable of mapping from composition and crystal structures to materials\nproperties. Generally, these are regression problems with the input being a 1D\nvector composed of numerical attributes representing the material composition\nand/or crystal structure. While neural networks consisting of fully connected\nlayers have been applied to such problems, their performance often suffers from\nthe vanishing gradient problem when network depth is increased. In this paper,\nwe study and propose design principles for building deep regression networks\ncomposed of fully connected layers with numerical vectors as input. We\nintroduce a novel deep regression network with individual residual learning,\nIRNet, that places shortcut connections after each layer so that each layer\nlearns the residual mapping between its output and input. We use the problem of\nlearning properties of inorganic materials from numerical attributes derived\nfrom material composition and/or crystal structure to compare IRNet's\nperformance against that of other machine learning techniques. Using multiple\ndatasets from the Open Quantum Materials Database (OQMD) and Materials Project\nfor training and evaluation, we show that IRNet provides significantly better\nprediction performance than the state-of-the-art machine learning approaches\ncurrently used by domain scientists. We also show that IRNet's use of\nindividual residual learning leads to better convergence during the training\nphase than when shortcut connections are between multi-layer stacks while\nmaintaining the same number of parameters.",
    "published": "2019-07-07T05:19:35+00:00",
    "updated": "2019-07-07T05:19:35+00:00",
    "categories": [
      "physics.comp-ph",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "9 pages, under publication at KDD'19",
    "journal_ref": null,
    "doi": "10.1145/3292500.3330703",
    "pdf_url": "http://arxiv.org/pdf/1907.03222v1",
    "short_id": "1907.03222v1",
    "url": "http://arxiv.org/abs/1907.03222v1"
  }
]