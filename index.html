<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (4)</h2>
<p><em>Last updated: 2025-11-25 06:17:07 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Model Inversion Attack Against Deep Hashing<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Dongdong Zhao, Qiben Xu, Ranxin Fang, Baogang Song</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-15</p>
    <p class="paper-category"><strong>Category:</strong> cs.CV</p>
    <p class="paper-id"><strong>ID:</strong> 2511.12233v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.12233v2">http://arxiv.org/abs/2511.12233v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. RTMol: Rethinking Molecule-text Alignment in a Round-trip View<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Letian Chen, Runhan Shi, Gufeng Yu, Yang Yang</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-15</p>
    <p class="paper-category"><strong>Category:</strong> cs.AI</p>
    <p class="paper-id"><strong>ID:</strong> 2511.12135v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.12135v2">http://arxiv.org/abs/2511.12135v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">3. Quasiparticle states of hexagonal BN: A van der Waals density functional study<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Raul Quintero-Monsebaiz, Per Hyldgaard</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-20</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2511.16313v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.16313v2">http://arxiv.org/abs/2511.16313v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>We compute and track the impact of truly nonlocal-correlation effects on the quasi-particle (QP) band-structure of hexagonal boron-nitride (h-BN) systems. To that end, we start with the consistent-exchange vdW-DF-cx version [PRB 89, 035412 (2014)] of the van der Waals density functional (vdW-DF) method [JPCM 39, 390001 (2020)] for exchange-correlation (XC) functional design and enforce piece-wise linearity in the energy changes with partial charging, using the Koopmans-integer (KI) DFT framework [JCTC 19, 7079 (2023)]. Our approach and results (denoted KI-CX) extends present-standard use of KI DFT (denoted KI-PBE as it is based on the semilocal PBE [PRL 77, 3865 (1996)] XC functional) to capture, for example, the impact of the interlayer coupling on the QPs. We contrast KI-CX and KI-PBE results for the QP band-structure and compare with both $GW$ calculations and experimental observations of the (direct and indirect) QP gaps. We find that KI-CX brings improvements in the h-BN QP energy description and generally agrees with $GW$ studies.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">4. MRI Super-Resolution with Deep Learning: A Comprehensive Survey<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Mohammad Khateri, Serge Vasylechko, Morteza Ghahremani, Liam Timms, Deniz Kocanaogullari, Simon K. Warfield, Camilo Jaimes, Davood Karimi, Alejandra Sierra, Jussi Tohka, Sila Kurugol, Onur Afacan</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-20</p>
    <p class="paper-category"><strong>Category:</strong> eess.IV</p>
    <p class="paper-id"><strong>ID:</strong> 2511.16854v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.16854v1">http://arxiv.org/abs/2511.16854v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>High-resolution (HR) magnetic resonance imaging (MRI) is crucial for many clinical and research applications. However, achieving it remains costly and constrained by technical trade-offs and experimental limitations. Super-resolution (SR) presents a promising computational approach to overcome these challenges by generating HR images from more affordable low-resolution (LR) scans, potentially improving diagnostic accuracy and efficiency without requiring additional hardware. This survey reviews recent advances in MRI SR techniques, with a focus on deep learning (DL) approaches. It examines DL-based MRI SR methods from the perspectives of computer vision, computational imaging, inverse problems, and MR physics, covering theoretical foundations, architectural designs, learning strategies, benchmark datasets, and performance metrics. We propose a systematic taxonomy to categorize these methods and present an in-depth study of both established and emerging SR techniques applicable to MRI, considering unique challenges in clinical and research contexts. We also highlight open challenges and directions that the community needs to address. Additionally, we provide a collection of essential open-access resources, tools, and tutorials, available on our GitHub: https://github.com/mkhateri/Awesome-MRI-Super-Resolution.
  IEEE keywords: MRI, Super-Resolution, Deep Learning, Computational Imaging, Inverse Problem, Survey.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-11-25 06:17:07 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>