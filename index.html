<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (1)</h2>
<p><em>Last updated: 2025-10-10 06:15:37 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Tengwei Song, Min Wu, Yuan Fang</p>
    <p class="paper-date"><strong>Published:</strong> 2025-10-08</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2510.07035v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2510.07035v1">http://arxiv.org/abs/2510.07035v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Molecular representation learning plays a crucial role in advancing
applications such as drug discovery and material design. Existing work
leverages 2D and 3D modalities of molecular information for pre-training,
aiming to capture comprehensive structural and geometric insights. However,
these methods require paired 2D and 3D molecular data to train the model
effectively and prevent it from collapsing into a single modality, posing
limitations in scenarios where a certain modality is unavailable or
computationally expensive to generate. To overcome this limitation, we propose
FlexMol, a flexible molecule pre-training framework that learns unified
molecular representations while supporting single-modality input. Specifically,
inspired by the unified structure in vision-language models, our approach
employs separate models for 2D and 3D molecular data, leverages parameter
sharing to improve computational efficiency, and utilizes a decoder to generate
features for the missing modality. This enables a multistage continuous
learning process where both modalities contribute collaboratively during
training, while ensuring robustness when only one modality is available during
inference. Extensive experiments demonstrate that FlexMol achieves superior
performance across a wide range of molecular property prediction tasks, and we
also empirically demonstrate its effectiveness with incomplete data. Our code
and data are available at https://github.com/tewiSong/FlexMol.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-10-10 06:15:37 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>