<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (6)</h2>
<p><em>Last updated: 2025-11-27 06:17:25 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Ziyue Wang, Yayati Jadhav, Peter Pak, Amir Barati Farimani</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-25</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2511.20636v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.20636v1">http://arxiv.org/abs/2511.20636v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. Universe of Thoughts: Enabling Creative Reasoning with Large Language Models<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Yuto Suzuki, Farnoush Banaei-Kashani</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-25</p>
    <p class="paper-category"><strong>Category:</strong> cs.AI</p>
    <p class="paper-id"><strong>ID:</strong> 2511.20471v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.20471v1">http://arxiv.org/abs/2511.20471v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \textit{combinational}, \textit{exploratory}, and \textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or \textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">3. Diffusion for Fusion: Designing Stellarators with Generative AI<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Misha Padidar, Teresa Huang, Andrew Giuliani, Marina Spivak</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-25</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2511.20445v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.20445v1">http://arxiv.org/abs/2511.20445v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Stellarators are a prospective class of fusion-based power plants that confine a hot plasma with three-dimensional magnetic fields. Typically framed as a PDE-constrained optimization problem, stellarator design is a time-consuming process that can take hours to solve on a computing cluster. Developing fast methods for designing stellarators is crucial for advancing fusion research. Given the recent development of large datasets of optimized stellarators, machine learning approaches have emerged as a potential candidate. Motivated by this, we present an open inverse problem to the machine learning community: to rapidly generate high-quality stellarator designs which have a set of desirable characteristics. As a case study in the problem space, we train a conditional diffusion model on data from the QUASR database to generate quasisymmetric stellarator designs with desirable characteristics (aspect ratio and mean rotational transform). The diffusion model is applied to design stellarators with characteristics not seen during training. We provide evaluation protocols and show that many of the generated stellarators exhibit solid performance: less than 5% deviation from quasisymmetry and the target characteristics. The modest deviation from quasisymmetry highlights an opportunity to reach the sub 1% target. Beyond the case study, we share multiple promising avenues for generative modeling to advance stellarator design.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">4. KKL Observer Synthesis for Nonlinear Systems via Physics-Informed Learning<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> M. Umar B. Niazi, John Cao, Matthieu Barreau, Karl Henrik Johansson</p>
    <p class="paper-date"><strong>Published:</strong> 2025-01-20</p>
    <p class="paper-category"><strong>Category:</strong> eess.SY</p>
    <p class="paper-id"><strong>ID:</strong> 2501.11655v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2501.11655v2">http://arxiv.org/abs/2501.11655v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>This paper proposes a novel learning approach for designing Kazantzis-Kravaris/Luenberger (KKL) observers for autonomous nonlinear systems. The design of a KKL observer involves finding an injective map that transforms the system state into a higher-dimensional observer state, whose dynamics is linear and stable. The observer's state is then mapped back to the original system coordinates via the inverse map to obtain the state estimate. However, finding this transformation and its inverse is quite challenging. We propose learning the forward mapping using a physics-informed neural network, and then learning its inverse mapping with a conventional feedforward neural network. Theoretical guarantees for the robustness of state estimation against approximation error and system uncertainties are provided, including non-asymptotic learning guarantees that link approximation quality to finite sample sizes. The effectiveness of the proposed approach is demonstrated through numerical simulations on benchmark examples, showing superior generalization capability outside the training domain compared to state-of-the-art methods.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">5. iRadioDiff: Physics-Informed Diffusion Model for Indoor Radio Map Construction and Localization<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Xiucheng Wang, Tingwei Yuan, Yang Cao, Nan Cheng, Ruijin Sun, Weihua Zhuang</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-25</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2511.20015v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.20015v1">http://arxiv.org/abs/2511.20015v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Radio maps (RMs) serve as environment-aware electromagnetic (EM) representations that connect scenario geometry and material properties to the spatial distribution of signal strength, enabling localization without costly in-situ measurements. However, constructing high-fidelity indoor RMs remains challenging due to the prohibitive latency of EM solvers and the limitations of learning-based methods, which often rely on sparse measurements or assumptions of homogeneous material, which are misaligned with the heterogeneous and multipath-rich nature of indoor environments. To overcome these challenges, we propose iRadioDiff, a sampling-free diffusion-based framework for indoor RM construction. iRadioDiff is conditioned on access point (AP) positions, and physics-informed prompt encoded by material reflection and transmission coefficients. It further incorporates multipath-critical priors, including diffraction points, strong transmission boundaries, and line-of-sight (LoS) contours, to guide the generative process via conditional channels and boundary-weighted objectives. This design enables accurate modeling of nonstationary field discontinuities and efficient construction of physically consistent RMs. Experiments demonstrate that iRadioDiff achieves state-of-the-art performance in indoor RM construction and received signal strength based indoor localization, which offers effective generalization across layouts and material configurations. Code is available at https://github.com/UNIC-Lab/iRadioDiff.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">6. CycleChemist: A Dual-Pronged Machine Learning Framework for Organic Photovoltaic Discovery<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Hou Hei Lam, Jiangjie Qiu, Xiuyuan Hu, Wentao Li, Fankun Zeng, Siwei Fu, Hao Zhang, Xiaonan Wang</p>
    <p class="paper-date"><strong>Published:</strong> 2025-11-23</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2511.19500v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2511.19500v1">http://arxiv.org/abs/2511.19500v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Organic photovoltaic (OPV) materials offer a promising path toward sustainable energy generation, but their development is limited by the difficulty of identifying high performance donor and acceptor pairs with strong power conversion efficiencies (PCEs). Existing design strategies typically focus on either the donor or the acceptor alone, rather than using a unified approach capable of modeling both components. In this work, we introduce a dual machine learning framework for OPV discovery that combines predictive modeling with generative molecular design. We present the Organic Photovoltaic Donor Acceptor Dataset (OPV2D), the largest curated dataset of its kind, containing 2000 experimentally characterized donor acceptor pairs. Using this dataset, we develop the Organic Photovoltaic Classifier (OPVC) to predict whether a material exhibits OPV behavior, and a hierarchical graph neural network that incorporates multi task learning and donor acceptor interaction modeling. This framework includes the Molecular Orbital Energy Estimator (MOE2) for predicting HOMO and LUMO energy levels, and the Photovoltaic Performance Predictor (P3) for estimating PCE. In addition, we introduce the Material Generative Pretrained Transformer (MatGPT) to produce synthetically accessible organic semiconductors, guided by a reinforcement learning strategy with three objective policy optimization. By linking molecular representation learning with performance prediction, our framework advances data driven discovery of high performance OPV materials.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-11-27 06:17:25 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>