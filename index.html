<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (3)</h2>
<p><em>Last updated: 2025-10-18 06:15:49 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Learning Inter-Atomic Potentials without Explicit Equivariance<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Ahmed A. Elhag, Arun Raja, Alex Morehead, Samuel M. Blau, Garrett M. Morris, Michael M. Bronstein</p>
    <p class="paper-date"><strong>Published:</strong> 2025-09-25</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2510.00027v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2510.00027v2">http://arxiv.org/abs/2510.00027v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Accurate and scalable machine-learned inter-atomic potentials (MLIPs) are
essential for molecular simulations ranging from drug discovery to new material
design. Current state-of-the-art models enforce roto-translational symmetries
through equivariant neural network architectures, a hard-wired inductive bias
that can often lead to reduced flexibility, computational efficiency, and
scalability. In this work, we introduce TransIP: Transformer-based Inter-Atomic
Potentials, a novel training paradigm for interatomic potentials achieving
symmetry compliance without explicit architectural constraints. Our approach
guides a generic non-equivariant Transformer-based model to learn
SO(3)-equivariance by optimizing its representations in the embedding space.
Trained on the recent Open Molecules (OMol25) collection, a large and diverse
molecular dataset built specifically for MLIPs and covering different types of
molecules (including small organics, biomolecular fragments, and
electrolyte-like species), TransIP effectively learns symmetry in its latent
space, providing low equivariance error. Further, compared to a data
augmentation baseline, TransIP achieves 40% to 60% improvement in performance
across varying OMol25 dataset sizes. More broadly, our work shows that learned
equivariance can be a powerful and efficient alternative to augmentation-based
MLIP models.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. Strain-induced Moir√© Reconstruction and Memorization in Two-Dimensional Materials without Twist<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Nazmul Hasan, Tara Pe√±a, Aditya Dey, Dongyoung Yoon, Zakaria Islam, Yue Zhang, Maria Vitoria Guimaraes Leal, Arend M. van der Zande, Hesam Askari, Stephen M. Wu</p>
    <p class="paper-date"><strong>Published:</strong> 2025-10-15</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2510.13699v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2510.13699v1">http://arxiv.org/abs/2510.13699v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Two-dimensional (2D) materials with a twist between layers exhibit a moir\'e
interference pattern with larger periodicity than any of the constituent layer
unit cells. In these systems, a wealth of exotic phases appear that result from
moir\'e-dependent many-body electron correlation effects or non-trivial band
topology. One problem with using twist to generate moir\'e interference has
been the difficulty in creating high-quality, uniform, and repeatable samples
due to fabrication through mechanical stacking with viscoelastic stamps. Here
we show, a new method to generate moir\'e interference through the controlled
application of layer-by-layer strain (heterostrain) on non-twisted 2D
materials, where moir\'e interference results from strain-induced lattice
mismatch without twisting or stacking. Heterostrain generation is achieved by
depositing stressed thin films onto 2D materials to apply large strains to the
top layers while leaving layers further down less strained. We achieve
deterministic control of moir\'e periodicity and symmetry in non-twisted 2D
multilayers and bilayers, with 97% yield, through varying stressor film force
(film thickness X film stress) and geometry. Moir\'e reconstruction effects are
memorized after the removal of the stressor layers. Control over the strain
degree-of-freedom opens the door to a completely unexplored set of unrealized
tunable moir\'e geometric symmetries, which may now be achieved in a high-yield
and user-skill independent process taking only hours. This technique solves a
long-standing throughput bottleneck in new moir\'e quantum materials discovery
and opens the door to industrially-compatible manufacturing for 2D
moir\'e-based electronic or optical devices.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">3. Deep Generative Prior for First Order Inverse Optimization<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Haoyu Yang, Kamyar Azizzadenesheli, Haoxing Ren</p>
    <p class="paper-date"><strong>Published:</strong> 2025-04-28</p>
    <p class="paper-category"><strong>Category:</strong> cs.AI</p>
    <p class="paper-id"><strong>ID:</strong> 2504.20278v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2504.20278v2">http://arxiv.org/abs/2504.20278v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Inverse design optimization aims to infer system parameters from observed
solutions, posing critical challenges across domains such as semiconductor
manufacturing, structural engineering, materials science, and fluid dynamics.
The lack of explicit mathematical representations in many systems complicates
this process and makes the first order optimization impossible. Mainstream
approaches, including generative AI and Bayesian optimization, address these
challenges but have limitations. Generative AI is computationally expensive,
while Bayesian optimization, relying on surrogate models, suffers from
scalability, sensitivity to priors, and noise issues, often leading to
suboptimal solutions. This paper introduces Deep Physics Prior (DPP), a novel
method enabling first-order gradient-based inverse optimization with surrogate
machine learning models. By leveraging pretrained auxiliary Neural Operators,
DPP enforces prior distribution constraints to ensure robust and meaningful
solutions. This approach is particularly effective when prior data and
observation distributions are unknown.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-10-18 06:15:49 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>