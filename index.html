<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (23)</h2>
<p><em>Last updated: 2025-05-19 20:22:11 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Space Group Equivariant Crystal Diffusion</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Rees Chang, Angela Pak, Alex Guerra, Ni Zhan, Nick Richardson, Elif Ertekin, Ryan P. Adams</p>
    <p class="paper-date"><strong>Published:</strong> 2025-05-16</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2505.10994v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2505.10994v1">http://arxiv.org/abs/2505.10994v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Accelerating inverse design of crystalline materials with generative models
has significant implications for a range of technologies. Unlike other atomic
systems, 3D crystals are invariant to discrete groups of isometries called the
space groups. Crucially, these space group symmetries are known to heavily
influence materials properties. We propose SGEquiDiff, a crystal generative
model which naturally handles space group constraints with space group
invariant likelihoods. SGEquiDiff consists of an SE(3)-invariant, telescoping
discrete sampler of crystal lattices; permutation-invariant, transformer-based
autoregressive sampling of Wyckoff positions, elements, and numbers of
symmetrically unique atoms; and space group equivariant diffusion of atomic
coordinates. We show that space group equivariant vector fields automatically
live in the tangent spaces of the Wyckoff positions. SGEquiDiff achieves
state-of-the-art performance on standard benchmark datasets as assessed by
quantitative proxy metrics and quantum mechanical calculations.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. Design Topological Materials by Reinforcement Fine-Tuned Generative Model</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Haosheng Xu, Dongheng Qian, Zhixuan Liu, Yadong Jiang, Jing Wang</p>
    <p class="paper-date"><strong>Published:</strong> 2025-04-17</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2504.13048v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2504.13048v1">http://arxiv.org/abs/2504.13048v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Topological insulators (TIs) and topological crystalline insulators (TCIs)
are materials with unconventional electronic properties, making their discovery
highly valuable for practical applications. However, such materials,
particularly those with a full band gap, remain scarce. Given the limitations
of traditional approaches that scan known materials for candidates, we focus on
the generation of new topological materials through a generative model.
Specifically, we apply reinforcement fine-tuning (ReFT) to a pre-trained
generative model, thereby aligning the model's objectives with our material
design goals. We demonstrate that ReFT is effective in enhancing the model's
ability to generate TIs and TCIs, with minimal compromise on the stability of
the generated materials. Using the fine-tuned model, we successfully identify a
large number of new topological materials, with Ge$_2$Bi$_2$O$_6$ serving as a
representative example--a TI with a full band gap of 0.26 eV, ranking among the
largest known in this category.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">3. Force-Free Molecular Dynamics Through Autoregressive Equivariant Networks</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Fabian L. Thiemann, Thiago Resch√ºtzegger, Massimiliano Esposito, Tseden Taddese, Juan D. Olarte-Plata, Fausto Martelli</p>
    <p class="paper-date"><strong>Published:</strong> 2025-03-31</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 2503.23794v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2503.23794v1">http://arxiv.org/abs/2503.23794v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Molecular dynamics (MD) simulations play a crucial role in scientific
research. Yet their computational cost often limits the timescales and system
sizes that can be explored. Most data-driven efforts have been focused on
reducing the computational cost of accurate interatomic forces required for
solving the equations of motion. Despite their success, however, these machine
learning interatomic potentials (MLIPs) are still bound to small time-steps. In
this work, we introduce TrajCast, a transferable and data-efficient framework
based on autoregressive equivariant message passing networks that directly
updates atomic positions and velocities lifting the constraints imposed by
traditional numerical integration. We benchmark our framework across various
systems, including a small molecule, crystalline material, and bulk liquid,
demonstrating excellent agreement with reference MD simulations for structural,
dynamical, and energetic properties. Depending on the system, TrajCast allows
for forecast intervals up to $30\times$ larger than traditional MD time-steps,
generating over 15 ns of trajectory data per day for a solid with more than
4,000 atoms. By enabling efficient large-scale simulations over extended
timescales, TrajCast can accelerate materials discovery and explore physical
phenomena beyond the reach of traditional simulations and experiments. An
open-source implementation of TrajCast is accessible under
https://github.com/IBM/trajcast.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">4. deCIFer: Crystal Structure Prediction from Powder Diffraction Data using Autoregressive Language Models</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Frederik Lizak Johansen, Ulrik Friis-Jensen, Erik Bj√∏rnager Dam, Kirsten Marie √òrnsbjerg Jensen, Roc√≠o Mercado, Raghavendra Selvan</p>
    <p class="paper-date"><strong>Published:</strong> 2025-02-04</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2502.02189v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2502.02189v2">http://arxiv.org/abs/2502.02189v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Novel materials drive progress across applications from energy storage to
electronics. Automated characterization of material structures with machine
learning methods offers a promising strategy for accelerating this key step in
material design. In this work, we introduce an autoregressive language model
that performs crystal structure prediction (CSP) from powder diffraction data.
The presented model, deCIFer, generates crystal structures in the widely used
Crystallographic Information File (CIF) format and can be conditioned on powder
X-ray diffraction (PXRD) data. Unlike earlier works that primarily rely on
high-level descriptors like composition, deCIFer performs CSP from diffraction
data. We train deCIFer on nearly 2.3M unique crystal structures and validate on
diverse sets of PXRD patterns for characterizing challenging inorganic crystal
systems. Qualitative and quantitative assessments using the residual weighted
profile and Wasserstein distance show that deCIFer produces structures that
more accurately match the target diffraction data when conditioned, compared to
the unconditioned case. Notably, deCIFer can achieve a 94% match rate on unseen
data. deCIFer bridges experimental diffraction data with computational CSP,
lending itself as a powerful tool for crystal structure characterization and
accelerating materials discovery.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">5. A Periodic Bayesian Flow for Material Generation</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Hanlin Wu, Yuxuan Song, Jingjing Gong, Ziyao Cao, Yawen Ouyang, Jianbing Zhang, Hao Zhou, Wei-Ying Ma, Jingjing Liu</p>
    <p class="paper-date"><strong>Published:</strong> 2025-02-04</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2502.02016v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2502.02016v1">http://arxiv.org/abs/2502.02016v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Generative modeling of crystal data distribution is an important yet
challenging task due to the unique periodic physical symmetry of crystals.
Diffusion-based methods have shown early promise in modeling crystal
distribution. More recently, Bayesian Flow Networks were introduced to
aggregate noisy latent variables, resulting in a variance-reduced parameter
space that has been shown to be advantageous for modeling Euclidean data
distributions with structural constraints (Song et al., 2023). Inspired by
this, we seek to unlock its potential for modeling variables located in
non-Euclidean manifolds e.g. those within crystal structures, by overcoming
challenging theoretical issues. We introduce CrysBFN, a novel crystal
generation method by proposing a periodic Bayesian flow, which essentially
differs from the original Gaussian-based BFN by exhibiting non-monotonic
entropy dynamics. To successfully realize the concept of periodic Bayesian
flow, CrysBFN integrates a new entropy conditioning mechanism and empirically
demonstrates its significance compared to time-conditioning. Extensive
experiments over both crystal ab initio generation and crystal structure
prediction tasks demonstrate the superiority of CrysBFN, which consistently
achieves new state-of-the-art on all benchmarks. Surprisingly, we found that
CrysBFN enjoys a significant improvement in sampling efficiency, e.g., ~100x
speedup 10 v.s. 2000 steps network forwards) compared with previous
diffusion-based methods on MP-20 dataset. Code is available at
https://github.com/wu-han-lin/CrysBFN.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">6. Machine Learning Force-Field Approach for Itinerant Electron Magnets</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Sheng Zhang, Yunhao Fan, Kotaro Shimizu, Gia-Wei Chern</p>
    <p class="paper-date"><strong>Published:</strong> 2025-01-10</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.str-el</p>
    <p class="paper-id"><strong>ID:</strong> 2501.06171v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2501.06171v1">http://arxiv.org/abs/2501.06171v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>We review the recent development of machine-learning (ML) force-field
frameworks for Landau-Lifshitz-Gilbert (LLG) dynamics simulations of itinerant
electron magnets, focusing on the general theory and implementations of
symmetry-invariant representations of spin configurations. The crucial
properties that such magnetic descriptors must satisfy are differentiability
with respect to spin rotations and invariance to both lattice point-group
symmetry and internal spin rotation symmetry. We propose an efficient
implementation based on the concept of reference irreducible representations,
modified from the group-theoretical power-spectrum and bispectrum methods. The
ML framework is demonstrated using the s-d models, which are widely applied in
spintronics research. We show that LLG simulations based on local fields
predicted by the trained ML models successfully reproduce representative
non-collinear spin structures, including 120$^\circ$, tetrahedral, and skyrmion
crystal orders of the triangular-lattice s-d models. Large-scale thermal quench
simulations enabled by ML models further reveal intriguing freezing dynamics
and glassy stripe states consisting of skyrmions and bi-merons. Our work
highlights the utility of ML force-field approach to dynamical modeling of
complex spin orders in itinerant electron magnets.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">7. FastCHGNet: Training one Universal Interatomic Potential to 1.5 Hours with 32 GPUs</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Yuanchang Zhou, Siyu Hu, Chen Wang, Lin-Wang Wang, Guangming Tan, Weile Jia</p>
    <p class="paper-date"><strong>Published:</strong> 2024-12-30</p>
    <p class="paper-category"><strong>Category:</strong> cs.DC</p>
    <p class="paper-id"><strong>ID:</strong> 2412.20796v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2412.20796v2">http://arxiv.org/abs/2412.20796v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Graph neural network universal interatomic potentials (GNN-UIPs) have
demonstrated remarkable generalization and transfer capabilities in material
discovery and property prediction. These models can accelerate molecular
dynamics (MD) simulation by several orders of magnitude while maintaining
\textit{ab initio} accuracy, making them a promising new paradigm in material
simulations. One notable example is Crystal Hamiltonian Graph Neural Network
(CHGNet), pretrained on the energies, forces, stresses, and magnetic moments
from the MPtrj dataset, representing a state-of-the-art GNN-UIP model for
charge-informed MD simulations. However, training the CHGNet model is
time-consuming(8.3 days on one A100 GPU) for three reasons: (i) requiring
multi-layer propagation to reach more distant atom information, (ii) requiring
second-order derivatives calculation to finish weights updating and (iii) the
implementation of reference CHGNet does not fully leverage the computational
capabilities. This paper introduces FastCHGNet, an optimized CHGNet, with three
contributions: Firstly, we design innovative Force/Stress Readout modules to
decompose Force/Stress prediction. Secondly, we adopt massive optimizations
such as kernel fusion, redundancy bypass, etc, to exploit GPU computation power
sufficiently. Finally, we extend CHGNet to support multiple GPUs and propose a
load-balancing technique to enhance GPU utilization. Numerical results show
that FastCHGNet reduces memory footprint by a factor of 3.59. The final
training time of FastCHGNet can be decreased to \textbf{1.53 hours} on 32 GPUs
without sacrificing model accuracy.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">8. Large Language Model-Guided Prediction Toward Quantum Materials Synthesis</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Ryotaro Okabe, Zack West, Abhijatmedhi Chotrattanapituk, Mouyang Cheng, Denisse C√≥rdova Carrizales, Weiwei Xie, Robert J. Cava, Mingda Li</p>
    <p class="paper-date"><strong>Published:</strong> 2024-10-28</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2410.20976v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2410.20976v1">http://arxiv.org/abs/2410.20976v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>The synthesis of inorganic crystalline materials is essential for modern
technology, especially in quantum materials development. However, designing
efficient synthesis workflows remains a significant challenge due to the
precise experimental conditions and extensive trial and error. Here, we present
a framework using large language models (LLMs) to predict synthesis pathways
for inorganic materials, including quantum materials. Our framework contains
three models: LHS2RHS, predicting products from reactants; RHS2LHS, predicting
reactants from products; and TGT2CEQ, generating full chemical equations for
target compounds. Fine-tuned on a text-mined synthesis database, our model
raises accuracy from under 40% with pretrained models, to under 80% using
conventional fine-tuning, and further to around 90% with our proposed
generalized Tanimoto similarity, while maintaining robust to additional
synthesis steps. Our model further demonstrates comparable performance across
materials with varying degrees of quantumness quantified using quantum weight,
indicating that LLMs offer a powerful tool to predict balanced chemical
equations for quantum materials discovery.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">9. Learning Ordering in Crystalline Materials with Symmetry-Aware Graph Neural Networks</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Jiayu Peng, James Damewood, Jessica Karaguesian, Jaclyn R. Lunger, Rafael G√≥mez-Bombarelli</p>
    <p class="paper-date"><strong>Published:</strong> 2024-09-20</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2409.13851v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2409.13851v1">http://arxiv.org/abs/2409.13851v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Graph convolutional neural networks (GCNNs) have become a machine learning
workhorse for screening the chemical space of crystalline materials in fields
such as catalysis and energy storage, by predicting properties from structures.
Multicomponent materials, however, present a unique challenge since they can
exhibit chemical (dis)order, where a given lattice structure can encompass a
variety of elemental arrangements ranging from highly ordered structures to
fully disordered solid solutions. Critically, properties like stability,
strength, and catalytic performance depend not only on structures but also on
orderings. To enable rigorous materials design, it is thus critical to ensure
GCNNs are capable of distinguishing among atomic orderings. However, the
ordering-aware capability of GCNNs has been poorly understood. Here, we
benchmark various neural network architectures for capturing the
ordering-dependent energetics of multicomponent materials in a custom-made
dataset generated with high-throughput atomistic simulations. Conventional
symmetry-invariant GCNNs were found unable to discern the structural difference
between the diverse symmetrically inequivalent atomic orderings of the same
material, while symmetry-equivariant model architectures could inherently
preserve and differentiate the distinct crystallographic symmetries of various
orderings.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">10. Ab Initio Structure Solutions from Nanocrystalline Powder Diffraction Data</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Gabe Guo, Tristan Saidi, Maxwell Terban, Michele Valsecchi, Simon JL Billinge, Hod Lipson</p>
    <p class="paper-date"><strong>Published:</strong> 2024-06-16</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 2406.10796v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2406.10796v2">http://arxiv.org/abs/2406.10796v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>A major challenge in materials science is the determination of the structure
of nanometer sized objects. Here we present a novel approach that uses a
generative machine learning model based on diffusion processes that is trained
on 45,229 known structures. The model factors both the measured diffraction
pattern as well as relevant statistical priors on the unit cell of atomic
cluster structures. Conditioned only on the chemical formula and the
information-scarce finite-size broadened powder diffraction pattern, we find
that our model, PXRDnet, can successfully solve simulated nanocrystals as small
as 10 angstroms across 200 materials of varying symmetry and complexity,
including structures from all seven crystal systems. We show that our model can
successfully and verifiably determine structural candidates four out of five
times, with average error among these candidates being only 7% (as measured by
post-Rietveld refinement R-factor). Furthermore, PXRDnet is capable of solving
structures from noisy diffraction patterns gathered in real-world experiments.
We suggest that data driven approaches, bootstrapped from theoretical
simulation, will ultimately provide a path towards determining the structure of
previously unsolved nano-materials.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">11. Representing Molecules as Random Walks Over Interpretable Grammars</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Michael Sun, Minghao Guo, Weize Yuan, Veronika Thost, Crystal Elaine Owens, Aristotle Franklin Grosz, Sharvaa Selvan, Katelyn Zhou, Hassan Mohiuddin, Benjamin J Pedretti, Zachary P Smith, Jie Chen, Wojciech Matusik</p>
    <p class="paper-date"><strong>Published:</strong> 2024-03-13</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2403.08147v3</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2403.08147v3">http://arxiv.org/abs/2403.08147v3</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Recent research in molecular discovery has primarily been devoted to small,
drug-like molecules, leaving many similarly important applications in material
design without adequate technology. These applications often rely on more
complex molecular structures with fewer examples that are carefully designed
using known substructures. We propose a data-efficient and interpretable model
for representing and reasoning over such molecules in terms of graph grammars
that explicitly describe the hierarchical design space featuring motifs to be
the design basis. We present a novel representation in the form of random walks
over the design space, which facilitates both molecule generation and property
prediction. We demonstrate clear advantages over existing methods in terms of
performance, efficiency, and synthesizability of predicted molecules, and we
provide detailed insights into the method's chemical interpretability.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">12. CHILI: Chemically-Informed Large-scale Inorganic Nanomaterials Dataset for Advancing Graph Machine Learning</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Ulrik Friis-Jensen, Frederik L. Johansen, Andy S. Anker, Erik B. Dam, Kirsten M. √ò. Jensen, Raghavendra Selvan</p>
    <p class="paper-date"><strong>Published:</strong> 2024-02-20</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2402.13221v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2402.13221v2">http://arxiv.org/abs/2402.13221v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Advances in graph machine learning (ML) have been driven by applications in
chemistry as graphs have remained the most expressive representations of
molecules. While early graph ML methods focused primarily on small organic
molecules, recently, the scope of graph ML has expanded to include inorganic
materials. Modelling the periodicity and symmetry of inorganic crystalline
materials poses unique challenges, which existing graph ML methods are unable
to address. Moving to inorganic nanomaterials increases complexity as the scale
of number of nodes within each graph can be broad ($10$ to $10^5$). The bulk of
existing graph ML focuses on characterising molecules and materials by
predicting target properties with graphs as input. However, the most exciting
applications of graph ML will be in their generative capabilities, which is
currently not at par with other domains such as images or text.
  We invite the graph ML community to address these open challenges by
presenting two new chemically-informed large-scale inorganic (CHILI)
nanomaterials datasets: A medium-scale dataset (with overall >6M nodes, >49M
edges) of mono-metallic oxide nanomaterials generated from 12 selected crystal
types (CHILI-3K) and a large-scale dataset (with overall >183M nodes, >1.2B
edges) of nanomaterials generated from experimentally determined crystal
structures (CHILI-100K). We define 11 property prediction tasks and 6 structure
prediction tasks, which are of special interest for nanomaterial research. We
benchmark the performance of a wide array of baseline methods and use these
benchmarking results to highlight areas which need future work. To the best of
our knowledge, CHILI-3K and CHILI-100K are the first open-source nanomaterial
datasets of this scale -- both on the individual graph level and of the dataset
as a whole -- and the only nanomaterials datasets with high structural and
elemental diversity.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">13. Towards End-to-End Structure Solutions from Information-Compromised Diffraction Data via Generative Deep Learning</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Gabe Guo, Judah Goldfeder, Ling Lan, Aniv Ray, Albert Hanming Yang, Boyuan Chen, Simon JL Billinge, Hod Lipson</p>
    <p class="paper-date"><strong>Published:</strong> 2023-12-23</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 2312.15136v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2312.15136v1">http://arxiv.org/abs/2312.15136v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>The revolution in materials in the past century was built on a knowledge of
the atomic arrangements and the structure-property relationship. The sine qua
non for obtaining quantitative structural information is single crystal
crystallography. However, increasingly we need to solve structures in cases
where the information content in our input signal is significantly degraded,
for example, due to orientational averaging of grains, finite size effects due
to nanostructure, and mixed signals due to sample heterogeneity. Understanding
the structure property relationships in such situations is, if anything, more
important and insightful, yet we do not have robust approaches for
accomplishing it. In principle, machine learning (ML) and deep learning (DL)
are promising approaches since they augment information in the degraded input
signal with prior knowledge learned from large databases of already known
structures. Here we present a novel ML approach, a variational query-based
multi-branch deep neural network that has the promise to be a robust but
general tool to address this problem end-to-end. We demonstrate the approach on
computed powder x-ray diffraction (PXRD), along with partial chemical
composition information, as input. We choose as a structural representation a
modified electron density we call the Cartesian mapped electron density (CMED),
that straightforwardly allows our ML model to learn material structures across
different chemistries, symmetries and crystal systems. When evaluated on
theoretically simulated data for the cubic and trigonal crystal systems, the
system achieves up to $93.4\%$ average similarity with the ground truth on
unseen materials, both with known and partially-known chemical composition
information, showing great promise for successful structure solution even from
degraded and incomplete input data.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">14. Data Distillation for Neural Network Potentials toward Foundational Dataset</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Gang Seob Jung, Sangkeun Lee, Jong Youl Choi</p>
    <p class="paper-date"><strong>Published:</strong> 2023-11-09</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 2311.05407v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2311.05407v1">http://arxiv.org/abs/2311.05407v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Machine learning (ML) techniques and atomistic modeling have rapidly
transformed materials design and discovery. Specifically, generative models can
swiftly propose promising materials for targeted applications. However, the
predicted properties of materials through the generative models often do not
match with calculated properties through ab initio calculations. This
discrepancy can arise because the generated coordinates are not fully relaxed,
whereas the many properties are derived from relaxed structures. Neural
network-based potentials (NNPs) can expedite the process by providing relaxed
structures from the initially generated ones. Nevertheless, acquiring data to
train NNPs for this purpose can be extremely challenging as it needs to
encompass previously unknown structures. This study utilized extended ensemble
molecular dynamics (MD) to secure a broad range of liquid- and solid-phase
configurations in one of the metallic systems, nickel. Then, we could
significantly reduce them through active learning without losing much accuracy.
We found that the NNP trained from the distilled data could predict different
energy-minimized closed-pack crystal structures even though those structures
were not explicitly part of the initial data. Furthermore, the data can be
translated to other metallic systems (aluminum and niobium), without repeating
the sampling and distillation processes. Our approach to data acquisition and
distillation has demonstrated the potential to expedite NNP development and
enhance materials design and discovery by integrating generative models.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">15. Data-Driven Score-Based Models for Generating Stable Structures with Adaptive Crystal Cells</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Arsen Sultanov, Jean-Claude Crivello, Tabea Rebafka, Nataliya Sokolovska</p>
    <p class="paper-date"><strong>Published:</strong> 2023-10-16</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 2310.10695v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2310.10695v1">http://arxiv.org/abs/2310.10695v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>The discovery of new functional and stable materials is a big challenge due
to its complexity. This work aims at the generation of new crystal structures
with desired properties, such as chemical stability and specified chemical
composition, by using machine learning generative models. Compared to the
generation of molecules, crystal structures pose new difficulties arising from
the periodic nature of the crystal and from the specific symmetry constraints
related to the space group. In this work, score-based probabilistic models
based on annealed Langevin dynamics, which have shown excellent performance in
various applications, are adapted to the task of crystal generation. The
novelty of the presented approach resides in the fact that the lattice of the
crystal cell is not fixed. During the training of the model, the lattice is
learned from the available data, whereas during the sampling of a new chemical
structure, two denoising processes are used in parallel to generate the lattice
along the generation of the atomic positions. A multigraph crystal
representation is introduced that respects symmetry constraints, yielding
computational advantages and a better quality of the sampled structures. We
show that our model is capable of generating new candidate structures in any
chosen chemical system and crystal group without any additional training. To
illustrate the functionality of the proposed method, a comparison of our model
to other recent generative models, based on descriptor-based metrics, is
provided.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">16. Crystal-GFN: sampling crystals with desirable properties and constraints</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Mila AI4Science, Alex Hernandez-Garcia, Alexandre Duval, Alexandra Volokhova, Yoshua Bengio, Divya Sharma, Pierre Luc Carrier, Yasmine Benabed, Micha≈Ç Koziarski, Victor Schmidt</p>
    <p class="paper-date"><strong>Published:</strong> 2023-10-07</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2310.04925v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2310.04925v2">http://arxiv.org/abs/2310.04925v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Accelerating material discovery holds the potential to greatly help mitigate
the climate crisis. Discovering new solid-state materials such as
electrocatalysts, super-ionic conductors or photovoltaic materials can have a
crucial impact, for instance, in improving the efficiency of renewable energy
production and storage. In this paper, we introduce Crystal-GFN, a generative
model of crystal structures that sequentially samples structural properties of
crystalline materials, namely the space group, composition and lattice
parameters. This domain-inspired approach enables the flexible incorporation of
physical and structural hard constraints, as well as the use of any available
predictive model of a desired physicochemical property as an objective
function. To design stable materials, one must target the candidates with the
lowest formation energy. Here, we use as objective the formation energy per
atom of a crystal structure predicted by a new proxy machine learning model
trained on MatBench. The results demonstrate that Crystal-GFN is able to sample
highly diverse crystals with low (median -3.1 eV/atom) predicted formation
energy.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">17. Symmetry-Informed Geometric Representation for Molecules, Proteins, and Crystalline Materials</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Shengchao Liu, Weitao Du, Yanjing Li, Zhuoxinran Li, Zhiling Zheng, Chenru Duan, Zhiming Ma, Omar Yaghi, Anima Anandkumar, Christian Borgs, Jennifer Chayes, Hongyu Guo, Jian Tang</p>
    <p class="paper-date"><strong>Published:</strong> 2023-06-15</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2306.09375v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2306.09375v1">http://arxiv.org/abs/2306.09375v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Artificial intelligence for scientific discovery has recently generated
significant interest within the machine learning and scientific communities,
particularly in the domains of chemistry, biology, and material discovery. For
these scientific problems, molecules serve as the fundamental building blocks,
and machine learning has emerged as a highly effective and powerful tool for
modeling their geometric structures. Nevertheless, due to the rapidly evolving
process of the field and the knowledge gap between science (e.g., physics,
chemistry, & biology) and machine learning communities, a benchmarking study on
geometrical representation for such data has not been conducted. To address
such an issue, in this paper, we first provide a unified view of the current
symmetry-informed geometric methods, classifying them into three main
categories: invariance, equivariance with spherical frame basis, and
equivariance with vector frame basis. Then we propose a platform, coined
Geom3D, which enables benchmarking the effectiveness of geometric strategies.
Geom3D contains 16 advanced symmetry-informed geometric representation models
and 14 geometric pretraining methods over 46 diverse datasets, including small
molecules, proteins, and crystalline materials. We hope that Geom3D can, on the
one hand, eliminate barriers for machine learning researchers interested in
exploring scientific problems; and, on the other hand, provide valuable
guidance for researchers in computational chemistry, structural biology, and
materials science, aiding in the informed selection of representation
techniques for specific applications.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">18. Optimized Crystallographic Graph Generation for Material Science</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Astrid Klipfel, Ya√´l Fr√©gier, Adlane Sayede, Zied Bouraoui</p>
    <p class="paper-date"><strong>Published:</strong> 2023-06-07</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2307.05380v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2307.05380v1">http://arxiv.org/abs/2307.05380v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Graph neural networks are widely used in machine learning applied to
chemistry, and in particular for material science discovery. For crystalline
materials, however, generating graph-based representation from geometrical
information for neural networks is not a trivial task. The periodicity of
crystalline needs efficient implementations to be processed in real-time under
a massively parallel environment. With the aim of training graph-based
generative models of new material discovery, we propose an efficient tool to
generate cutoff graphs and k-nearest-neighbours graphs of periodic structures
within GPU optimization. We provide pyMatGraph a Pytorch-compatible framework
to generate graphs in real-time during the training of neural network
architecture. Our tool can update a graph of a structure, making generative
models able to update the geometry and process the updated graph during the
forward propagation on the GPU side. Our code is publicly available at
https://github.com/aklipf/mat-graph.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">19. Equivariant Message Passing Neural Network for Crystal Material Discovery</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Astrid Klipfel, Olivier Peltre, Najwa Harrati, Ya√´l Fregier, Adlane Sayede, Zied Bouraoui</p>
    <p class="paper-date"><strong>Published:</strong> 2023-02-01</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2302.00485v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2302.00485v1">http://arxiv.org/abs/2302.00485v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Automatic material discovery with desired properties is a fundamental
challenge for material sciences. Considerable attention has recently been
devoted to generating stable crystal structures. While existing work has shown
impressive success on supervised tasks such as property prediction, the
progress on unsupervised tasks such as material generation is still hampered by
the limited extent to which the equivalent geometric representations of the
same crystal are considered. To address this challenge, we propose EMPNN a
periodic equivariant message-passing neural network that learns crystal lattice
deformation in an unsupervised fashion. Our model equivalently acts on lattice
according to the deformation action that must be performed, making it suitable
for crystal generation, relaxation and optimisation. We present experimental
evaluations that demonstrate the effectiveness of our approach.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">20. Unified theory of atom-centered representations and message-passing machine-learning schemes</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Jigyasa Nigam, Sergey Pozdnyakov, Guillaume Fraux, Michele Ceriotti</p>
    <p class="paper-date"><strong>Published:</strong> 2022-02-03</p>
    <p class="paper-category"><strong>Category:</strong> stat.ML</p>
    <p class="paper-id"><strong>ID:</strong> 2202.01566v3</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2202.01566v3">http://arxiv.org/abs/2202.01566v3</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Data-driven schemes that associate molecular and crystal structures with
their microscopic properties share the need for a concise, effective
description of the arrangement of their atomic constituents. Many types of
models rely on descriptions of atom-centered environments, that are associated
with an atomic property or with an atomic contribution to an extensive
macroscopic quantity. Frameworks in this class can be understood in terms of
atom-centered density correlations (ACDC), that are used as a basis for a
body-ordered, symmetry-adapted expansion of the targets. Several other schemes,
that gather information on the relationship between neighboring atoms using
"message-passing" ideas, cannot be directly mapped to correlations centered
around a single atom. We generalize the ACDC framework to include
multi-centered information, generating representations that provide a complete
linear basis to regress symmetric functions of atomic coordinates, and provides
a coherent foundation to systematize our understanding of both atom-centered
and message-passing, invariant and equivariant machine-learning schemes.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">21. Deep Generative Model for Periodic Graphs</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Shiyu Wang, Xiaojie Guo, Liang Zhao</p>
    <p class="paper-date"><strong>Published:</strong> 2022-01-28</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2201.11932v4</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2201.11932v4">http://arxiv.org/abs/2201.11932v4</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Periodic graphs are graphs consisting of repetitive local structures, such as
crystal nets and polygon mesh. Their generative modeling has great potential in
real-world applications such as material design and graphics synthesis.
Classical models either rely on domain-specific predefined generation
principles (e.g., in crystal net design), or follow geometry-based prescribed
rules. Recently, deep generative models has shown great promise in
automatically generating general graphs. However, their advancement into
periodic graphs have not been well explored due to several key challenges in 1)
maintaining graph periodicity; 2) disentangling local and global patterns; and
3) efficiency in learning repetitive patterns. To address them, this paper
proposes Periodical-Graph Disentangled Variational Auto-encoder (PGD-VAE), a
new deep generative models for periodic graphs that can automatically learn,
disentangle, and generate local and global graph patterns. Specifically, we
develop a new periodic graph encoder consisting of global-pattern encoder and
local-pattern encoder that ensures to disentangle the representation into
global and local semantics. We then propose a new periodic graph decoder
consisting of local structure decoder, neighborhood decoder, and global
structure decoder, as well as the assembler of their outputs that guarantees
periodicity. Moreover, we design a new model learning objective that helps
ensure the invariance of local-semantic representations for the graphs with the
same local structure. Comprehensive experimental evaluations have been
conducted to demonstrate the effectiveness of the proposed method. The code of
proposed PGD-VAE is availabe at https://github.com/shi-yu-wang/PGD-VAE.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">22. Deep Learning for Bayesian Optimization of Scientific Problems with High-Dimensional Structure</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Samuel Kim, Peter Y. Lu, Charlotte Loh, Jamie Smith, Jasper Snoek, Marin Soljaƒçiƒá</p>
    <p class="paper-date"><strong>Published:</strong> 2021-04-23</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2104.11667v4</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2104.11667v4">http://arxiv.org/abs/2104.11667v4</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Bayesian optimization (BO) is a popular paradigm for global optimization of
expensive black-box functions, but there are many domains where the function is
not completely a black-box. The data may have some known structure (e.g.
symmetries) and/or the data generation process may be a composite process that
yields useful intermediate or auxiliary information in addition to the value of
the optimization objective. However, surrogate models traditionally employed in
BO, such as Gaussian Processes (GPs), scale poorly with dataset size and do not
easily accommodate known structure. Instead, we use Bayesian neural networks, a
class of scalable and flexible surrogate models with inductive biases, to
extend BO to complex, structured problems with high dimensionality. We
demonstrate BO on a number of realistic problems in physics and chemistry,
including topology optimization of photonic crystal materials using
convolutional neural networks, and chemical property optimization of molecules
using graph neural networks. On these complex tasks, we show that neural
networks often outperform GPs as surrogate models for BO in terms of both
sampling efficiency and computational cost.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">23. IRNet: A General Purpose Deep Residual Regression Framework for Materials Discovery</h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Dipendra Jha, Logan Ward, Zijiang Yang, Christopher Wolverton, Ian Foster, Wei-keng Liao, Alok Choudhary, Ankit Agrawal</p>
    <p class="paper-date"><strong>Published:</strong> 2019-07-07</p>
    <p class="paper-category"><strong>Category:</strong> physics.comp-ph</p>
    <p class="paper-id"><strong>ID:</strong> 1907.03222v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/1907.03222v1">http://arxiv.org/abs/1907.03222v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Materials discovery is crucial for making scientific advances in many
domains. Collections of data from experiments and first-principle computations
have spurred interest in applying machine learning methods to create predictive
models capable of mapping from composition and crystal structures to materials
properties. Generally, these are regression problems with the input being a 1D
vector composed of numerical attributes representing the material composition
and/or crystal structure. While neural networks consisting of fully connected
layers have been applied to such problems, their performance often suffers from
the vanishing gradient problem when network depth is increased. In this paper,
we study and propose design principles for building deep regression networks
composed of fully connected layers with numerical vectors as input. We
introduce a novel deep regression network with individual residual learning,
IRNet, that places shortcut connections after each layer so that each layer
learns the residual mapping between its output and input. We use the problem of
learning properties of inorganic materials from numerical attributes derived
from material composition and/or crystal structure to compare IRNet's
performance against that of other machine learning techniques. Using multiple
datasets from the Open Quantum Materials Database (OQMD) and Materials Project
for training and evaluation, we show that IRNet provides significantly better
prediction performance than the state-of-the-art machine learning approaches
currently used by domain scientists. We also show that IRNet's use of
individual residual learning leads to better convergence during the training
phase than when shortcut connections are between multi-layer stacks while
maintaining the same number of parameters.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-05-19 20:22:11 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>