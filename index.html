<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (2)</h2>
<p><em>Last updated: 2025-10-23 06:14:10 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Uncovering critical temperature dependence in Heusler magnets via explicit machine learning<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Jean-Baptiste Mor√©e, Juba Bouaziz, Ryotaro Arita</p>
    <p class="paper-date"><strong>Published:</strong> 2025-10-21</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2510.18469v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2510.18469v1">http://arxiv.org/abs/2510.18469v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>We employ interpretable explicit machine learning to analyze the material
dependence of the magnetic transition temperature $T_c$ in ferromagnetic and
ferrimagnetic Heusler compounds. For around 200 compounds, we consider both
experimental $T_c$ and calculated $T_c$ using \textit{ab initio} determination
of magnetic interactions together with a Monte-Carlo solution. We use the
hierarchical dependence extraction (HDE) procedure [Mor\'ee and Arita, Phys.
Rev. B 110, 014502 (2024)] to extract the dependencies of $T_c$ on chemical
proportions and magnetic moments from the main order to the higher order, and
construct an explicit expression of $T_c$ from these dependencies. The main
results are: (a) $T_c$ is mainly controlled by the proportions of Fe, Co, and
Mn, and increases with these proportions, consistent with previous machine
learning analyses of ferromagnetic materials. (b) The HDE describes $T_c$ with
an accuracy that is comparable to that of other machine learning procedures.
(c) The HDE expression of $T_c$ can be interpreted as a generalized order
parameter that increases with increasing magnetization amplitude, in
qualitative agreement with various theories of phase transitions. These results
strengthen our understanding of the material dependence of $T_c$ in collinear
Heusler magnets and motivate the further use of HDE in material design.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. Enabling Automatic Differentiation with Mollified Graph Neural Operators<br><span style='color:orange;font-weight:bold;'>üîÑ Updated</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Ryan Y. Lin, Julius Berner, Valentin Duruisseaux, David Pitt, Daniel Leibovici, Jean Kossaifi, Kamyar Azizzadenesheli, Anima Anandkumar</p>
    <p class="paper-date"><strong>Published:</strong> 2025-04-11</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2504.08277v2</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2504.08277v2">http://arxiv.org/abs/2504.08277v2</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Physics-informed neural operators offer a powerful framework for learning
solution operators of partial differential equations (PDEs) by combining data
and physics losses. However, these physics losses rely on derivatives.
Computing these derivatives remains challenging, with spectral and finite
difference methods introducing approximation errors due to finite resolution.
Here, we propose the mollified graph neural operator ($m$GNO), the first method
to leverage automatic differentiation and compute exact gradients on arbitrary
geometries. This enhancement enables efficient training on irregular grids and
varying geometries while allowing seamless evaluation of physics losses at
randomly sampled points for improved generalization. For a PDE example on
regular grids, $m$GNO paired with autograd reduced the L2 relative data error
by 20x compared to finite differences, although training was slower. It can
also solve PDEs on unstructured point clouds seamlessly, using physics losses
only, at resolutions vastly lower than those needed for finite differences to
be accurate enough. On these unstructured point clouds, $m$GNO leads to errors
that are consistently 2 orders of magnitude lower than machine learning
baselines (Meta-PDE, which accelerates PINNs) for comparable runtimes, and also
delivers speedups from 1 to 3 orders of magnitude compared to the numerical
solver for similar accuracy. $m$GNOs can also be used to solve inverse design
and shape optimization problems on complex geometries.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-10-23 06:14:10 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>