<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-F3PL2Q961N"></script>
    <script src="static/js/gtag-init.js"></script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv Daily - Latest Papers</title>
    <link rel="stylesheet" href="static/css/style.css">
    <link rel="stylesheet" href="static/css/dark-mode.css">
    <link rel="icon" type="image/x-icon" href="static/favicon_io/favicon.ico">
    <link rel="icon" type="image/png" sizes="16x16" href="static/favicon_io/favicon-16x16.png">
    <link rel="icon" type="image/png" sizes="32x32" href="static/favicon_io/favicon-32x32.png">
    <link rel="apple-touch-icon" sizes="180x180" href="static/favicon_io/apple-touch-icon.png">
</head>
<body>
<!-- Toggle Button -->
<button id="theme-toggle">üåô Night</button>

<a href="https://ocean-jh.github.io/" target="_blank" class="top-left-logo">
    <img src="static/favicon_io/logo.png" alt="Wang Jianghai's Blog" class="blog-logo">
</a>

<div class="header">
    <h1>ArXiv Daily - AI for Materials Science!</h1>
    <p>Discover the latest research at the intersection of <strong>Artificial Intelligence</strong> and <strong>Materials
        Science</strong>.</p>
    <p>Every day, we track and curate new papers from <a href="https://arxiv.org" target="_blank">arXiv.org</a>,
        focusing on cutting-edge innovations in materials discovery, design, and prediction powered by AI and machine
        learning.</p>
    <p>üîé Updated daily ‚Äî Powered by automation, driven by curiosity.</p>
</div>

    
    <div class="nav">
        <strong>Latest Papers</strong> | <a href="archive.html">View Archive</a>
    </div>
    

    <!-- Search Container -->
    <div class="search-container">
        <input type="text" id="search-input" placeholder="Search papers by title, author, or summary...">
        <button id="search-button">üîç Search</button>
    </div>

    <!-- Main Content -->
    <h2>New Papers (3)</h2>
<p><em>Last updated: 2025-10-02 06:15:40 SGT</em></p>
<div class="paper">
  <h3 class="paper-title">1. Fine-Tuning Bulk-oriented Universal Interatomic Potentials for Surfaces: Accuracy, Efficiency, and Forgetting Control<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Jaekyun Hwang, Taehun Lee, Yonghyuk Lee, Su-Hyun Yoo</p>
    <p class="paper-date"><strong>Published:</strong> 2025-09-30</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.mtrl-sci</p>
    <p class="paper-id"><strong>ID:</strong> 2509.25807v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2509.25807v1">http://arxiv.org/abs/2509.25807v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Accurate prediction of surface energies and stabilities is essential for
materials design, yet first-principles calculations remain computationally
expensive and most existing interatomic potentials are trained only on bulk
systems. Here, we demonstrate that fine-tuning foundation machine learning
potentials (MLPs) significantly improves both computational efficiency and
predictive accuracy for surface modeling. While existing universal interatomic
potentials (UIPs) have been solely trained and validated on bulk datasets, we
extend their applicability to complex and scientifically significant unary,
binary, and ternary surface systems. We systematically compare models trained
from scratch, zero-shot inference, conventional fine-tuning, and multi-head
fine-tuning approach that enhances transferability and mitigates catastrophic
forgetting. Fine-tuning consistently reduces prediction errors with
orders-of-magnitude fewer training configurations, and multi-head fine-tuning
delivers robust and generalizable predictions even for materials beyond the
initial training domain. These findings offer practical guidance for leveraging
pre-trained MLPs to accelerate surface modeling and highlight a scalable path
toward data-efficient, next-generation atomic-scale simulations in
computational materials science.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">2. Steering an Active Learning Workflow Towards Novel Materials Discovery via Queue Prioritization<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Marcus Schwarting, Logan Ward, Nathaniel Hudson, Xiaoli Yan, Ben Blaiszik, Santanu Chaudhuri, Eliu Huerta, Ian Foster</p>
    <p class="paper-date"><strong>Published:</strong> 2025-09-29</p>
    <p class="paper-category"><strong>Category:</strong> cs.LG</p>
    <p class="paper-id"><strong>ID:</strong> 2509.25538v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2509.25538v1">http://arxiv.org/abs/2509.25538v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>Generative AI poses both opportunities and risks for solving inverse design
problems in the sciences. Generative tools provide the ability to expand and
refine a search space autonomously, but do so at the cost of exploring
low-quality regions until sufficiently fine tuned. Here, we propose a queue
prioritization algorithm that combines generative modeling and active learning
in the context of a distributed workflow for exploring complex design spaces.
We find that incorporating an active learning model to prioritize top design
candidates can prevent a generative AI workflow from expending resources on
nonsensical candidates and halt potential generative model decay. For an
existing generative AI workflow for discovering novel molecular structure
candidates for carbon capture, our active learning approach significantly
increases the number of high-quality candidates identified by the generative
model. We find that, out of 1000 novel candidates, our workflow without active
learning can generate an average of 281 high-performing candidates, while our
proposed prioritization with active learning can generate an average 604
high-performing candidates.</p>
  </details>

  <hr class="paper-divider">
</div><div class="paper">
  <h3 class="paper-title">3. Guided Diffusion for the Discovery of New Superconductors<br><span style='color:yellow;font-weight:bold;'>üåü New</span><br></h3>

  <div class="paper-info">
    <p class="paper-authors"><strong>Authors:</strong> Pawan Prakash, Jason B. Gibson, Zhongwei Li, Gabriele Di Gianluca, Juan Esquivel, Eric Fuemmeler, Benjamin Geisler, Jung Soo Kim, Adrian Roitberg, Ellad B. Tadmor, Mingjie Liu, Stefano Martiniani, Gregory R. Stewart, James J. Hamlin, Peter J. Hirschfeld, Richard G. Hennig</p>
    <p class="paper-date"><strong>Published:</strong> 2025-09-29</p>
    <p class="paper-category"><strong>Category:</strong> cond-mat.supr-con</p>
    <p class="paper-id"><strong>ID:</strong> 2509.25186v1</p>
  </div>

  <p class="paper-link"><strong>Link:</strong> <a href="http://arxiv.org/abs/2509.25186v1">http://arxiv.org/abs/2509.25186v1</a></p>

  <details class="paper-summary">
    <summary>Summary (Click to Expand)</summary>
    <p>The inverse design of materials with specific desired properties, such as
high-temperature superconductivity, represents a formidable challenge in
materials science due to the vastness of chemical and structural space. We
present a guided diffusion framework to accelerate the discovery of novel
superconductors. A DiffCSP foundation model is pretrained on the Alexandria
Database and fine-tuned on 7,183 superconductors with first principles derived
labels. Employing classifier-free guidance, we sample 200,000 structures, which
lead to 34,027 unique candidates. A multistage screening process that combines
machine learning and density functional theory (DFT) calculations to assess
stability and electronic properties, identifies 773 candidates with
DFT-calculated $T_\mathrm{c}>5$ K. Notably, our generative model demonstrates
effective property-driven design. Our computational findings were validated
against experimental synthesis and characterization performed as part of this
work, which highlighted challenges in sparsely charted chemistries. This
end-to-end workflow accelerates superconductor discovery while underscoring the
challenge of predicting and synthesizing experimentally realizable materials.</p>
  </details>

  <hr class="paper-divider">
</div>

    <footer>
        <p>Last updated: 2025-10-02 06:15:40 (SGT)</p>
        <p>2025 <a href="https://ocean-jh.github.io/" target="_blank">Wang Jianghai</a><a href="mailto:jianghai001@e.ntu.edu.sg">üìß</a> @ Nanyang Technological University | All Rights Reserved</p>
        <p><a href="https://github.com/Ocean-JH/ArXivDaily-AI4MAT">Star on GitHub</a></p>
        <p>Powered by <a href="https://arxiv.org/" target="_blank">arXiv</a> ¬∑ Updated Daily</p>
    </footer>

    <button id="back-to-top" title="Back to Top">‚Üë</button>

    <!-- JavaScript -->
    <script src="static/js/dark-mode.js"></script>
    <script src="static/js/search.js"></script>
    <script src="static/js/back-to-top.js"></script>
</body>
</html>